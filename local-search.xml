<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>CUDA_Grid_Block_threadIdx映射计算</title>
    <link href="/2025/12/28/GPU/00_CUDA_Grid_Block_threadIdx%E6%98%A0%E5%B0%84%E8%AE%A1%E7%AE%97/"/>
    <url>/2025/12/28/GPU/00_CUDA_Grid_Block_threadIdx%E6%98%A0%E5%B0%84%E8%AE%A1%E7%AE%97/</url>
    
    <content type="html"><![CDATA[<h1 id="CUDA-Grid、Block、ThreadIdx映射计算"><a href="#CUDA-Grid、Block、ThreadIdx映射计算" class="headerlink" title="CUDA Grid、Block、ThreadIdx映射计算"></a>CUDA Grid、Block、ThreadIdx映射计算</h1><p>CUDA是NVIDIA推出的并行计算平台和编程模型，它允许开发者利用GPU的并行计算能力。在CUDA编程中，理解线程层次结构以及如何将线程映射到计算任务是非常重要的。</p><h2 id="1-CUDA线程层次结构"><a href="#1-CUDA线程层次结构" class="headerlink" title="1. CUDA线程层次结构"></a>1. CUDA线程层次结构</h2><p>CUDA采用了三层线程层次结构：Grid（网格）、Block（块）和Thread（线程）。</p><ul><li><strong>Grid（网格）</strong>：是由多个Block组成的集合，可以是1D、2D或3D结构</li><li><strong>Block（块）</strong>：是由多个Thread组成的集合，同样可以是1D、2D或3D结构</li><li><strong>Thread（线程）</strong>：是CUDA中最小的执行单元，每个线程执行核函数的一部分计算</li></ul><p><img src="https://developer.nvidia.com/sites/default/files/pictures/2017/cuda_arch2.png" alt="CUDA线程层次结构"></p><p>（注：以上是NVIDIA官方CUDA线程层次结构示意图，展示了Grid、Block和Thread之间的关系）</p><p>在CUDA核函数中，我们可以通过以下内置变量获取当前线程的位置信息：</p><ul><li><code>blockIdx.x/y/z</code>：当前Block在Grid中的索引</li><li><code>blockDim.x/y/z</code>：每个Block中的Thread数量</li><li><code>threadIdx.x/y/z</code>：当前Thread在Block中的索引</li><li><code>gridDim.x/y/z</code>：Grid中的Block数量</li></ul><p>接下来，我们将详细介绍不同维度（1D、2D、3D）的Grid和Block如何映射到实际的计算任务，并通过代码示例展示如何计算线程ID。</p><h2 id="2-1D-Grid和1D-Block映射计算"><a href="#2-1D-Grid和1D-Block映射计算" class="headerlink" title="2. 1D Grid和1D Block映射计算"></a>2. 1D Grid和1D Block映射计算</h2><p>1D Grid和1D Block是最简单的线程映射方式，通常用于处理一维数据结构（如向量）。</p><h3 id="2-1-映射原理"><a href="#2-1-映射原理" class="headerlink" title="2.1 映射原理"></a>2.1 映射原理</h3><p>在1D映射中：</p><ul><li>Grid由多个1D Block组成</li><li>每个Block由多个1D Thread组成</li><li>线程ID计算公式：<code>thread_id = blockIdx.x * blockDim.x + threadIdx.x</code></li></ul><h3 id="2-2-图示"><a href="#2-2-图示" class="headerlink" title="2.2 图示"></a>2.2 图示</h3><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs mathematica"><span class="hljs-built_in">Grid</span> <span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-built_in">D</span><span class="hljs-punctuation">)</span><br>┌─────────────────────────────────────────────────────────┐<br>│ <span class="hljs-built_in">Block</span> <span class="hljs-number">0</span> │ <span class="hljs-built_in">Block</span> <span class="hljs-number">1</span> │ <span class="hljs-operator">...</span> │ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-variable">gridDim</span><span class="hljs-operator">.</span><span class="hljs-variable">x</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span>           │<br>└─────────┴─────────┴─────┴───────────────────────────────┘<br>  │         │             │<br>  ▼         ▼             ▼<br>┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐<br>│ <span class="hljs-built_in">Thread</span> <span class="hljs-number">0</span>        │ │ <span class="hljs-built_in">Thread</span> <span class="hljs-number">0</span>        │ │ <span class="hljs-built_in">Thread</span> <span class="hljs-number">0</span>        │<br>│ <span class="hljs-built_in">Thread</span> <span class="hljs-number">1</span>        │ │ <span class="hljs-built_in">Thread</span> <span class="hljs-number">1</span>        │ │ <span class="hljs-built_in">Thread</span> <span class="hljs-number">1</span>        │<br>│ <span class="hljs-operator">...</span>             │ │ <span class="hljs-operator">...</span>             │ │ <span class="hljs-operator">...</span>             │<br>│ <span class="hljs-built_in">Thread</span> <span class="hljs-punctuation">(</span><span class="hljs-variable">blockDim</span><span class="hljs-operator">.</span><span class="hljs-variable">x</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span> │ │ <span class="hljs-built_in">Thread</span> <span class="hljs-punctuation">(</span><span class="hljs-variable">blockDim</span><span class="hljs-operator">.</span><span class="hljs-variable">x</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span> │ │ <span class="hljs-built_in">Thread</span> <span class="hljs-punctuation">(</span><span class="hljs-variable">blockDim</span><span class="hljs-operator">.</span><span class="hljs-variable">x</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span> │<br>└─────────────────┘ └─────────────────┘ └─────────────────┘<br></code></pre></td></tr></table></figure><p>（注：以上ASCII图展示了1D Grid和1D Block的结构，Grid包含多个Block，每个Block包含多个Thread）</p><h3 id="2-3-代码示例"><a href="#2-3-代码示例" class="headerlink" title="2.3 代码示例"></a>2.3 代码示例</h3><p>下面的代码示例展示了如何使用1D Grid和1D Block计算向量加法：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cuda_runtime.h&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> N 1024</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> BLOCK_SIZE 256</span><br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">vector_add_1d</span><span class="hljs-params">(<span class="hljs-type">float</span>* a, <span class="hljs-type">float</span>* b, <span class="hljs-type">float</span>* c)</span> </span>&#123;<br>    <span class="hljs-comment">// 计算当前线程的全局ID</span><br>    <span class="hljs-type">int</span> thread_id = blockIdx.x * blockDim.x + threadIdx.x;<br>    <br>    <span class="hljs-comment">// 确保线程ID不超过向量长度</span><br>    <span class="hljs-keyword">if</span> (thread_id &lt; N) &#123;<br>        c[thread_id] = a[thread_id] + b[thread_id];<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-comment">// 分配主机内存</span><br>    <span class="hljs-type">float</span>* h_a = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N];<br>    <span class="hljs-type">float</span>* h_b = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N];<br>    <span class="hljs-type">float</span>* h_c = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N];<br>    <br>    <span class="hljs-comment">// 初始化数据</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; ++i) &#123;<br>        h_a[i] = <span class="hljs-number">1.0f</span>;<br>        h_b[i] = <span class="hljs-number">2.0f</span>;<br>    &#125;<br>    <br>    <span class="hljs-comment">// 分配设备内存</span><br>    <span class="hljs-type">float</span>* d_a, * d_b, * d_c;<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_a, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_b, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_c, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>    <br>    <span class="hljs-comment">// 数据从主机复制到设备</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(d_a, h_a, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyHostToDevice);<br>    <span class="hljs-built_in">cudaMemcpy</span>(d_b, h_b, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyHostToDevice);<br>    <br>    <span class="hljs-comment">// 计算Grid大小</span><br>    <span class="hljs-type">int</span> grid_size = (N + BLOCK_SIZE - <span class="hljs-number">1</span>) / BLOCK_SIZE;<br>    <br>    <span class="hljs-comment">// 启动核函数</span><br>    vector_add_1d&lt;&lt;&lt;grid_size, BLOCK_SIZE&gt;&gt;&gt;(d_a, d_b, d_c);<br>    <br>    <span class="hljs-comment">// 结果从设备复制到主机</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(h_c, d_c, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyDeviceToHost);<br>    <br>    <span class="hljs-comment">// 验证结果</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; ++i) &#123;<br>        std::cout &lt;&lt; <span class="hljs-string">&quot;c[&quot;</span> &lt;&lt; i &lt;&lt; <span class="hljs-string">&quot;] = &quot;</span> &lt;&lt; h_c[i] &lt;&lt; std::endl;<br>    &#125;<br>    <br>    <span class="hljs-comment">// 释放内存</span><br>    <span class="hljs-keyword">delete</span>[] h_a;<br>    <span class="hljs-keyword">delete</span>[] h_b;<br>    <span class="hljs-keyword">delete</span>[] h_c;<br>    <span class="hljs-built_in">cudaFree</span>(d_a);<br>    <span class="hljs-built_in">cudaFree</span>(d_b);<br>    <span class="hljs-built_in">cudaFree</span>(d_c);<br>    <br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>在这个示例中：</p><ul><li>我们创建了两个长度为1024的向量<code>a</code>和<code>b</code></li><li>使用1D Grid和1D Block启动核函数，每个线程计算一个向量元素的和</li><li>线程ID通过<code>thread_id = blockIdx.x * blockDim.x + threadIdx.x</code>计算</li><li>确保线程ID不超过向量长度，避免越界访问</li></ul><h2 id="3-2D-Grid和2D-Block映射计算"><a href="#3-2D-Grid和2D-Block映射计算" class="headerlink" title="3. 2D Grid和2D Block映射计算"></a>3. 2D Grid和2D Block映射计算</h2><p>2D Grid和2D Block是最常用的线程映射方式之一，特别适合处理二维数据结构（如矩阵）。</p><h3 id="3-1-映射原理"><a href="#3-1-映射原理" class="headerlink" title="3.1 映射原理"></a>3.1 映射原理</h3><p>在2D映射中：</p><ul><li>Grid由多个2D Block组成（可以看作是Block的矩阵）</li><li>每个Block由多个2D Thread组成（可以看作是Thread的矩阵）</li><li>行索引计算公式：<code>row = blockIdx.y * blockDim.y + threadIdx.y</code></li><li>列索引计算公式：<code>col = blockIdx.x * blockDim.x + threadIdx.x</code></li></ul><h3 id="3-2-图示"><a href="#3-2-图示" class="headerlink" title="3.2 图示"></a>3.2 图示</h3><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs scss"><span class="hljs-attribute">Grid</span> (<span class="hljs-number">2</span>D)<br>┌─────────────────────────────────────────────────────────┐<br>│ Block (<span class="hljs-number">0</span>,<span class="hljs-number">0</span>) │ Block (<span class="hljs-number">1</span>,<span class="hljs-number">0</span>) │ ... │ Block (gridDim.x-<span class="hljs-number">1</span>,<span class="hljs-number">0</span>) │<br>├─────────────┼─────────────┼─────┼───────────────────────┤<br>│ Block (<span class="hljs-number">0</span>,<span class="hljs-number">1</span>) │ Block (<span class="hljs-number">1</span>,<span class="hljs-number">1</span>) │ ... │ Block (gridDim.x-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>) │<br>├─────────────┼─────────────┼─────┼───────────────────────┤<br>│ ...         │ ...         │ ... │ ...                   │<br>├─────────────┼─────────────┼─────┼───────────────────────┤<br>│ Block (<span class="hljs-number">0</span>,gridDim.y-<span class="hljs-number">1</span>) │ Block (<span class="hljs-number">1</span>,gridDim.y-<span class="hljs-number">1</span>) │ ... │ Block (gridDim.x-<span class="hljs-number">1</span>,gridDim.y-<span class="hljs-number">1</span>) │<br>└─────────────┴─────────────┴─────┴───────────────────────┘<br>        │               │                         │<br>        ▼               ▼                         ▼<br>┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐<br>│ Thread (<span class="hljs-number">0</span>,<span class="hljs-number">0</span>)    │ │ Thread (<span class="hljs-number">0</span>,<span class="hljs-number">0</span>)    │ │ Thread (<span class="hljs-number">0</span>,<span class="hljs-number">0</span>)    │<br>│ Thread (<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)    │ │ Thread (<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)    │ │ Thread (<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)    │<br>│ ...             │ │ ...             │ │ ...             │<br>│ Thread (blockDim.x-<span class="hljs-number">1</span>,<span class="hljs-number">0</span>) │ │ Thread (blockDim.x-<span class="hljs-number">1</span>,<span class="hljs-number">0</span>) │ │ Thread (blockDim.x-<span class="hljs-number">1</span>,<span class="hljs-number">0</span>) │<br>├─────────────────┤ ├─────────────────┤ ├─────────────────┤<br>│ Thread (<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)    │ │ Thread (<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)    │ │ Thread (<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)    │<br>│ Thread (<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)    │ │ Thread (<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)    │ │ Thread (<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)    │<br>│ ...             │ │ ...             │ │ ...             │<br>│ Thread (blockDim.x-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>) │ │ Thread (blockDim.x-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>) │ │ Thread (blockDim.x-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>) │<br>├─────────────────┤ ├─────────────────┤ ├─────────────────┤<br>│ ...             │ │ ...             │ │ ...             │<br>├─────────────────┤ ├─────────────────┤ ├─────────────────┤<br>│ Thread (<span class="hljs-number">0</span>,blockDim.y-<span class="hljs-number">1</span>) │ │ Thread (<span class="hljs-number">0</span>,blockDim.y-<span class="hljs-number">1</span>) │ │ Thread (<span class="hljs-number">0</span>,blockDim.y-<span class="hljs-number">1</span>) │<br>│ Thread (<span class="hljs-number">1</span>,blockDim.y-<span class="hljs-number">1</span>) │ │ Thread (<span class="hljs-number">1</span>,blockDim.y-<span class="hljs-number">1</span>) │ │ Thread (<span class="hljs-number">1</span>,blockDim.y-<span class="hljs-number">1</span>) │<br>│ ...             │ │ ...             │ │ ...             │<br>│ Thread (blockDim.x-<span class="hljs-number">1</span>,blockDim.y-<span class="hljs-number">1</span>) │ │ Thread (blockDim.x-<span class="hljs-number">1</span>,blockDim.y-<span class="hljs-number">1</span>) │ │ Thread (blockDim.x-<span class="hljs-number">1</span>,blockDim.y-<span class="hljs-number">1</span>) │<br>└─────────────────┘ └─────────────────┘ └─────────────────┘<br></code></pre></td></tr></table></figure><p>（注：以上ASCII图展示了2D Grid和2D Block的结构，Grid是一个Block的矩阵，每个Block是一个Thread的矩阵）</p><h3 id="3-3-代码示例"><a href="#3-3-代码示例" class="headerlink" title="3.3 代码示例"></a>3.3 代码示例</h3><p>下面的代码示例展示了如何使用2D Grid和2D Block计算矩阵加法：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cuda_runtime.h&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> N 1024</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> BLOCK_SIZE 16</span><br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">matrix_add_2d</span><span class="hljs-params">(<span class="hljs-type">float</span>* a, <span class="hljs-type">float</span>* b, <span class="hljs-type">float</span>* c, <span class="hljs-type">int</span> n)</span> </span>&#123;<br>    <span class="hljs-comment">// 计算当前线程的行列索引</span><br>    <span class="hljs-type">int</span> row = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-type">int</span> col = blockIdx.x * blockDim.x + threadIdx.x;<br>    <br>    <span class="hljs-comment">// 确保行列索引不超过矩阵大小</span><br>    <span class="hljs-keyword">if</span> (row &lt; n &amp;&amp; col &lt; n) &#123;<br>        <span class="hljs-type">int</span> index = row * n + col;<br>        c[index] = a[index] + b[index];<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-type">int</span> size = N * N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>    <br>    <span class="hljs-comment">// 分配主机内存</span><br>    <span class="hljs-type">float</span>* h_a = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N * N];<br>    <span class="hljs-type">float</span>* h_b = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N * N];<br>    <span class="hljs-type">float</span>* h_c = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N * N];<br>    <br>    <span class="hljs-comment">// 初始化数据</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N * N; ++i) &#123;<br>        h_a[i] = <span class="hljs-number">1.0f</span>;<br>        h_b[i] = <span class="hljs-number">2.0f</span>;<br>    &#125;<br>    <br>    <span class="hljs-comment">// 分配设备内存</span><br>    <span class="hljs-type">float</span>* d_a, * d_b, * d_c;<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_a, size);<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_b, size);<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_c, size);<br>    <br>    <span class="hljs-comment">// 数据从主机复制到设备</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(d_a, h_a, size, cudaMemcpyHostToDevice);<br>    <span class="hljs-built_in">cudaMemcpy</span>(d_b, h_b, size, cudaMemcpyHostToDevice);<br>    <br>    <span class="hljs-comment">// 计算Grid和Block大小</span><br>    <span class="hljs-function">dim3 <span class="hljs-title">block_size</span><span class="hljs-params">(BLOCK_SIZE, BLOCK_SIZE)</span></span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">grid_size</span><span class="hljs-params">((N + block_size.x - <span class="hljs-number">1</span>) / block_size.x, (N + block_size.y - <span class="hljs-number">1</span>) / block_size.y)</span></span>;<br>    <br>    <span class="hljs-comment">// 启动核函数</span><br>    matrix_add_2d&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_a, d_b, d_c, N);<br>    <br>    <span class="hljs-comment">// 结果从设备复制到主机</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(h_c, d_c, size, cudaMemcpyDeviceToHost);<br>    <br>    <span class="hljs-comment">// 验证结果</span><br>    std::cout &lt;&lt; <span class="hljs-string">&quot;Matrix addition results (first 5x5):&quot;</span> &lt;&lt; std::endl;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">5</span>; ++i) &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; <span class="hljs-number">5</span>; ++j) &#123;<br>            <span class="hljs-type">int</span> index = i * N + j;<br>            std::cout &lt;&lt; h_c[index] &lt;&lt; <span class="hljs-string">&quot; &quot;</span>;<br>        &#125;<br>        std::cout &lt;&lt; std::endl;<br>    &#125;<br>    <br>    <span class="hljs-comment">// 释放内存</span><br>    <span class="hljs-keyword">delete</span>[] h_a;<br>    <span class="hljs-keyword">delete</span>[] h_b;<br>    <span class="hljs-keyword">delete</span>[] h_c;<br>    <span class="hljs-built_in">cudaFree</span>(d_a);<br>    <span class="hljs-built_in">cudaFree</span>(d_b);<br>    <span class="hljs-built_in">cudaFree</span>(d_c);<br>    <br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>在这个示例中：</p><ul><li>我们创建了两个1024x1024的矩阵<code>a</code>和<code>b</code></li><li>使用2D Grid和2D Block启动核函数，每个线程计算矩阵中对应位置元素的和</li><li>行索引通过<code>row = blockIdx.y * blockDim.y + threadIdx.y</code>计算</li><li>列索引通过<code>col = blockIdx.x * blockDim.x + threadIdx.x</code>计算</li><li>使用<code>dim3</code>类型来定义2D的Grid和Block大小</li><li>确保行列索引不超过矩阵大小，避免越界访问</li></ul><h2 id="4-3D-Grid和3D-Block映射计算"><a href="#4-3D-Grid和3D-Block映射计算" class="headerlink" title="4. 3D Grid和3D Block映射计算"></a>4. 3D Grid和3D Block映射计算</h2><p>3D Grid和3D Block用于处理三维数据结构（如体积、张量等），是CUDA中最复杂但功能最强大的线程映射方式。</p><h3 id="4-1-映射原理"><a href="#4-1-映射原理" class="headerlink" title="4.1 映射原理"></a>4.1 映射原理</h3><p>在3D映射中：</p><ul><li>Grid由多个3D Block组成（可以看作是Block的立方体）</li><li>每个Block由多个3D Thread组成（可以看作是Thread的立方体）</li><li>x坐标计算公式：<code>x = blockIdx.x * blockDim.x + threadIdx.x</code></li><li>y坐标计算公式：<code>y = blockIdx.y * blockDim.y + threadIdx.y</code></li><li>z坐标计算公式：<code>z = blockIdx.z * blockDim.z + threadIdx.z</code></li></ul><h3 id="4-2-图示"><a href="#4-2-图示" class="headerlink" title="4.2 图示"></a>4.2 图示</h3><p>3D结构在文本中难以完全展示，我们可以将其分解为多个z层来理解：</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs mathematica"><span class="hljs-built_in">Grid</span> <span class="hljs-punctuation">(</span><span class="hljs-number">3</span><span class="hljs-built_in">D</span><span class="hljs-punctuation">)</span> <span class="hljs-operator">-</span> 分解为<span class="hljs-variable">z</span><span class="hljs-operator">=</span><span class="hljs-number">0</span>和<span class="hljs-variable">z</span><span class="hljs-operator">=</span><span class="hljs-number">1</span>层<br><br><span class="hljs-variable">z</span><span class="hljs-operator">=</span><span class="hljs-number">0</span>层<span class="hljs-operator">:</span><br>┌─────────────────────────────────────────────────────────┐<br>│ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span> │ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span> │ <span class="hljs-operator">...</span> │ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-variable">gridDim</span><span class="hljs-operator">.</span><span class="hljs-variable">x</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span> │<br>├─────────────┼─────────────┼─────┼───────────────────────────┤<br>│ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span> │ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span> │ <span class="hljs-operator">...</span> │ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-variable">gridDim</span><span class="hljs-operator">.</span><span class="hljs-variable">x</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span> │<br>├─────────────┼─────────────┼─────┼───────────────────────────┤<br>│ <span class="hljs-operator">...</span>         │ <span class="hljs-operator">...</span>         │ <span class="hljs-operator">...</span> │ <span class="hljs-operator">...</span>                       │<br>├─────────────┼─────────────┼─────┼───────────────────────────┤<br>│ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-variable">gridDim</span><span class="hljs-operator">.</span><span class="hljs-variable">y</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span> │ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-variable">gridDim</span><span class="hljs-operator">.</span><span class="hljs-variable">y</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span> │ <span class="hljs-operator">...</span> │ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-variable">gridDim</span><span class="hljs-operator">.</span><span class="hljs-variable">x</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-variable">gridDim</span><span class="hljs-operator">.</span><span class="hljs-variable">y</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span> │<br>└─────────────┴─────────────┴─────┴───────────────────────────┘<br><br><span class="hljs-variable">z</span><span class="hljs-operator">=</span><span class="hljs-number">1</span>层<span class="hljs-operator">:</span><br>┌─────────────────────────────────────────────────────────┐<br>│ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span> │ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span> │ <span class="hljs-operator">...</span> │ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-variable">gridDim</span><span class="hljs-operator">.</span><span class="hljs-variable">x</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span> │<br>├─────────────┼─────────────┼─────┼───────────────────────────┤<br>│ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span> │ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span> │ <span class="hljs-operator">...</span> │ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-variable">gridDim</span><span class="hljs-operator">.</span><span class="hljs-variable">x</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span> │<br>├─────────────┼─────────────┼─────┼───────────────────────────┤<br>│ <span class="hljs-operator">...</span>         │ <span class="hljs-operator">...</span>         │ <span class="hljs-operator">...</span> │ <span class="hljs-operator">...</span>                       │<br>├─────────────┼─────────────┼─────┼───────────────────────────┤<br>│ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-variable">gridDim</span><span class="hljs-operator">.</span><span class="hljs-variable">y</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span> │ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-variable">gridDim</span><span class="hljs-operator">.</span><span class="hljs-variable">y</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span> │ <span class="hljs-operator">...</span> │ <span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-variable">gridDim</span><span class="hljs-operator">.</span><span class="hljs-variable">x</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-variable">gridDim</span><span class="hljs-operator">.</span><span class="hljs-variable">y</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span> │<br>└─────────────┴─────────────┴─────┴───────────────────────────┘<br><br>每个<span class="hljs-built_in">Block</span>内部结构（以<span class="hljs-built_in">Block</span> <span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span>为例）：<br>┌─────────────────┐<br>│ <span class="hljs-built_in">Thread</span> <span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span>  │<br>│ <span class="hljs-built_in">Thread</span> <span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span>  │<br>│ <span class="hljs-operator">...</span>             │<br>│ <span class="hljs-built_in">Thread</span> <span class="hljs-punctuation">(</span><span class="hljs-variable">blockDim</span><span class="hljs-operator">.</span><span class="hljs-variable">x</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span> │<br>├─────────────────┤<br>│ <span class="hljs-built_in">Thread</span> <span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span>  │<br>│ <span class="hljs-built_in">Thread</span> <span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span>  │<br>│ <span class="hljs-operator">...</span>             │<br>│ <span class="hljs-built_in">Thread</span> <span class="hljs-punctuation">(</span><span class="hljs-variable">blockDim</span><span class="hljs-operator">.</span><span class="hljs-variable">x</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span> │<br>├─────────────────┤<br>│ <span class="hljs-operator">...</span>             │<br>├─────────────────┤<br>│ <span class="hljs-built_in">Thread</span> <span class="hljs-punctuation">(</span><span class="hljs-number">0</span><span class="hljs-operator">,</span><span class="hljs-variable">blockDim</span><span class="hljs-operator">.</span><span class="hljs-variable">y</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span> │<br>│ <span class="hljs-built_in">Thread</span> <span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-variable">blockDim</span><span class="hljs-operator">.</span><span class="hljs-variable">y</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span> │<br>│ <span class="hljs-operator">...</span>             │<br>│ <span class="hljs-built_in">Thread</span> <span class="hljs-punctuation">(</span><span class="hljs-variable">blockDim</span><span class="hljs-operator">.</span><span class="hljs-variable">x</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-variable">blockDim</span><span class="hljs-operator">.</span><span class="hljs-variable">y</span><span class="hljs-operator">-</span><span class="hljs-number">1</span><span class="hljs-operator">,</span><span class="hljs-number">0</span><span class="hljs-punctuation">)</span> │<br>├─────────────────┤<br>│ <span class="hljs-operator">...</span>             │  <span class="hljs-operator">&lt;--</span> <span class="hljs-variable">z</span>方向延伸<br>└─────────────────┘<br></code></pre></td></tr></table></figure><p>（注：以上ASCII图展示了3D Grid和3D Block的结构，Grid是一个Block的立方体，每个Block是一个Thread的立方体）</p><h3 id="4-3-代码示例"><a href="#4-3-代码示例" class="headerlink" title="4.3 代码示例"></a>4.3 代码示例</h3><p>下面的代码示例展示了如何使用3D Grid和3D Block计算3D体积加法：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cuda_runtime.h&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> N 32  <span class="hljs-comment">// 3D体积的大小 (N x N x N)</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> BLOCK_SIZE 4</span><br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">volume_add_3d</span><span class="hljs-params">(<span class="hljs-type">float</span>* a, <span class="hljs-type">float</span>* b, <span class="hljs-type">float</span>* c, <span class="hljs-type">int</span> n)</span> </span>&#123;<br>    <span class="hljs-comment">// 计算当前线程的三维坐标</span><br>    <span class="hljs-type">int</span> x = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">int</span> y = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-type">int</span> z = blockIdx.z * blockDim.z + threadIdx.z;<br>    <br>    <span class="hljs-comment">// 确保坐标不超过体积大小</span><br>    <span class="hljs-keyword">if</span> (x &lt; n &amp;&amp; y &lt; n &amp;&amp; z &lt; n) &#123;<br>        <span class="hljs-comment">// 计算一维索引</span><br>        <span class="hljs-type">int</span> index = z * n * n + y * n + x;<br>        c[index] = a[index] + b[index];<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-type">int</span> size = N * N * N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>    <br>    <span class="hljs-comment">// 分配主机内存</span><br>    <span class="hljs-type">float</span>* h_a = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N * N * N];<br>    <span class="hljs-type">float</span>* h_b = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N * N * N];<br>    <span class="hljs-type">float</span>* h_c = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N * N * N];<br>    <br>    <span class="hljs-comment">// 初始化数据</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N * N * N; ++i) &#123;<br>        h_a[i] = <span class="hljs-number">1.0f</span>;<br>        h_b[i] = <span class="hljs-number">2.0f</span>;<br>    &#125;<br>    <br>    <span class="hljs-comment">// 分配设备内存</span><br>    <span class="hljs-type">float</span>* d_a, * d_b, * d_c;<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_a, size);<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_b, size);<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_c, size);<br>    <br>    <span class="hljs-comment">// 数据从主机复制到设备</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(d_a, h_a, size, cudaMemcpyHostToDevice);<br>    <span class="hljs-built_in">cudaMemcpy</span>(d_b, h_b, size, cudaMemcpyHostToDevice);<br>    <br>    <span class="hljs-comment">// 计算Grid和Block大小</span><br>    <span class="hljs-function">dim3 <span class="hljs-title">block_size</span><span class="hljs-params">(BLOCK_SIZE, BLOCK_SIZE, BLOCK_SIZE)</span></span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">grid_size</span><span class="hljs-params">((N + block_size.x - <span class="hljs-number">1</span>) / block_size.x, </span></span><br><span class="hljs-params"><span class="hljs-function">                  (N + block_size.y - <span class="hljs-number">1</span>) / block_size.y, </span></span><br><span class="hljs-params"><span class="hljs-function">                  (N + block_size.z - <span class="hljs-number">1</span>) / block_size.z)</span></span>;<br>    <br>    <span class="hljs-comment">// 启动核函数</span><br>    volume_add_3d&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_a, d_b, d_c, N);<br>    <br>    <span class="hljs-comment">// 结果从设备复制到主机</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(h_c, d_c, size, cudaMemcpyDeviceToHost);<br>    <br>    <span class="hljs-comment">// 验证结果</span><br>    std::cout &lt;&lt; <span class="hljs-string">&quot;3D Volume addition results (selected voxels):&quot;</span> &lt;&lt; std::endl;<br>    <span class="hljs-comment">// 验证几个关键点的结果</span><br>    <span class="hljs-type">int</span> test_points[<span class="hljs-number">5</span>][<span class="hljs-number">3</span>] = &#123;&#123;<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>&#125;, &#123;N/<span class="hljs-number">2</span>, N/<span class="hljs-number">2</span>, N/<span class="hljs-number">2</span>&#125;, &#123;N<span class="hljs-number">-1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>&#125;, &#123;<span class="hljs-number">0</span>, N<span class="hljs-number">-1</span>, <span class="hljs-number">0</span>&#125;, &#123;<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, N<span class="hljs-number">-1</span>&#125;&#125;;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">5</span>; ++i) &#123;<br>        <span class="hljs-type">int</span> x = test_points[i][<span class="hljs-number">0</span>];<br>        <span class="hljs-type">int</span> y = test_points[i][<span class="hljs-number">1</span>];<br>        <span class="hljs-type">int</span> z = test_points[i][<span class="hljs-number">2</span>];<br>        <span class="hljs-type">int</span> index = z * N * N + y * N + x;<br>        std::cout &lt;&lt; <span class="hljs-string">&quot;c[&quot;</span> &lt;&lt; x &lt;&lt; <span class="hljs-string">&quot;,&quot;</span> &lt;&lt; y &lt;&lt; <span class="hljs-string">&quot;,&quot;</span> &lt;&lt; z &lt;&lt; <span class="hljs-string">&quot;] = &quot;</span> &lt;&lt; h_c[index] &lt;&lt; std::endl;<br>    &#125;<br>    <br>    <span class="hljs-comment">// 释放内存</span><br>    <span class="hljs-keyword">delete</span>[] h_a;<br>    <span class="hljs-keyword">delete</span>[] h_b;<br>    <span class="hljs-keyword">delete</span>[] h_c;<br>    <span class="hljs-built_in">cudaFree</span>(d_a);<br>    <span class="hljs-built_in">cudaFree</span>(d_b);<br>    <span class="hljs-built_in">cudaFree</span>(d_c);<br>    <br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>在这个示例中：</p><ul><li>我们创建了两个32x32x32的3D体积<code>a</code>和<code>b</code></li><li>使用3D Grid和3D Block启动核函数，每个线程计算体积中对应位置体素的和</li><li>三维坐标通过以下公式计算：<ul><li><code>x = blockIdx.x * blockDim.x + threadIdx.x</code></li><li><code>y = blockIdx.y * blockDim.y + threadIdx.y</code></li><li><code>z = blockIdx.z * blockDim.z + threadIdx.z</code></li></ul></li><li>使用<code>dim3</code>类型来定义3D的Grid和Block大小</li><li>确保三维坐标不超过体积大小，避免越界访问</li></ul><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h2><p>CUDA线程映射是CUDA编程的核心概念之一，它决定了如何将计算任务分配给GPU上的大量线程。本文详细介绍了不同维度的Grid和Block映射计算方法：</p><h3 id="5-1-线程ID计算总结"><a href="#5-1-线程ID计算总结" class="headerlink" title="5.1 线程ID计算总结"></a>5.1 线程ID计算总结</h3><table><thead><tr><th>维度</th><th>坐标计算</th><th>适用场景</th></tr></thead><tbody><tr><td>1D</td><td><code>thread_id = blockIdx.x * blockDim.x + threadIdx.x</code></td><td>向量运算、一维数组处理</td></tr><tr><td>2D</td><td><code>row = blockIdx.y * blockDim.y + threadIdx.y</code><br><code>col = blockIdx.x * blockDim.x + threadIdx.x</code></td><td>矩阵运算、图像处理</td></tr><tr><td>3D</td><td><code>x = blockIdx.x * blockDim.x + threadIdx.x</code><br><code>y = blockIdx.y * blockDim.y + threadIdx.y</code><br><code>z = blockIdx.z * blockDim.z + threadIdx.z</code></td><td>3D体积处理、张量运算</td></tr></tbody></table><h3 id="5-2-关键要点"><a href="#5-2-关键要点" class="headerlink" title="5.2 关键要点"></a>5.2 关键要点</h3><ol><li><strong>Grid和Block的维度选择</strong>：根据数据结构的维度选择合适的Grid和Block维度，可以提高代码的可读性和性能</li><li><strong>线程数量计算</strong>：Grid大小应该根据数据大小和Block大小来计算，确保所有数据都能被处理：<ul><li>1D: <code>grid_size = (data_size + block_size - 1) / block_size</code></li><li>2D: <code>grid_size.x = (width + block_size.x - 1) / block_size.x</code><br><code>grid_size.y = (height + block_size.y - 1) / block_size.y</code></li><li>3D: <code>grid_size.x = (depth + block_size.x - 1) / block_size.x</code><br><code>grid_size.y = (height + block_size.y - 1) / block_size.y</code><br><code>grid_size.z = (width + block_size.z - 1) / block_size.z</code></li></ul></li><li><strong>边界检查</strong>：始终需要检查计算出的线程ID是否超出数据范围，避免越界访问</li><li><strong><code>dim3</code>类型</strong>：使用<code>dim3</code>类型可以方便地定义多维的Grid和Block大小</li></ol><h3 id="5-3-性能考虑"><a href="#5-3-性能考虑" class="headerlink" title="5.3 性能考虑"></a>5.3 性能考虑</h3><ul><li><strong>Block大小选择</strong>：通常选择32、64、128或256等2的幂作为Block大小，可以更好地利用GPU的硬件资源</li><li><strong>内存访问模式</strong>：合理的线程映射可以优化内存访问模式，提高缓存命中率</li><li><strong>共享内存使用</strong>：结合共享内存可以进一步提高性能，特别是在处理二维和三维数据结构时</li></ul><p>通过本文的学习，您应该能够理解CUDA线程层次结构，并根据不同的计算任务选择合适的线程映射方式。在实际应用中，需要根据具体问题灵活选择Grid和Block的维度，并结合其他CUDA优化技术（如共享内存、流等）来获得最佳性能。</p>]]></content>
    
    
    <categories>
      
      <category>GPU</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>CUDA_矩阵乘运算从CPU到GPU</title>
    <link href="/2025/12/28/GPU/01_CUDA_%E7%9F%A9%E9%98%B5%E4%B9%98%E8%BF%90%E7%AE%97%E4%BB%8ECPU%E5%88%B0GPU/"/>
    <url>/2025/12/28/GPU/01_CUDA_%E7%9F%A9%E9%98%B5%E4%B9%98%E8%BF%90%E7%AE%97%E4%BB%8ECPU%E5%88%B0GPU/</url>
    
    <content type="html"><![CDATA[<h1 id="CUDA矩阵乘运算从CPU到GPU"><a href="#CUDA矩阵乘运算从CPU到GPU" class="headerlink" title="CUDA矩阵乘运算从CPU到GPU"></a>CUDA矩阵乘运算从CPU到GPU</h1><p>矩阵乘法是计算机科学中最基础且应用广泛的运算之一。本文将详细介绍如何将矩阵乘法从CPU迁移到GPU，并通过CUDA实现不同级别的优化。</p><h2 id="1-CPU版本矩阵乘法"><a href="#1-CPU版本矩阵乘法" class="headerlink" title="1. CPU版本矩阵乘法"></a>1. CPU版本矩阵乘法</h2><p>首先，我们来看一个简单的CPU版本矩阵乘法实现，作为基准对比：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;chrono&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> N 1024</span><br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">matrix_multiply_cpu</span><span class="hljs-params">(<span class="hljs-type">float</span>* A, <span class="hljs-type">float</span>* B, <span class="hljs-type">float</span>* C)</span> </span>&#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; ++i) &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; N; ++j) &#123;<br>            <span class="hljs-type">float</span> sum = <span class="hljs-number">0.0f</span>;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> k = <span class="hljs-number">0</span>; k &lt; N; ++k) &#123;<br>                sum += A[i * N + k] * B[k * N + j];<br>            &#125;<br>            C[i * N + j] = sum;<br>        &#125;<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-comment">// 分配内存</span><br>    <span class="hljs-type">float</span>* A = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N * N];<br>    <span class="hljs-type">float</span>* B = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N * N];<br>    <span class="hljs-type">float</span>* C = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N * N];<br>    <br>    <span class="hljs-comment">// 初始化数据</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N * N; ++i) &#123;<br>        A[i] = <span class="hljs-number">1.0f</span>;<br>        B[i] = <span class="hljs-number">2.0f</span>;<br>        C[i] = <span class="hljs-number">0.0f</span>;<br>    &#125;<br>    <br>    <span class="hljs-comment">// 计时开始</span><br>    <span class="hljs-keyword">auto</span> start = std::chrono::high_resolution_clock::<span class="hljs-built_in">now</span>();<br>    <br>    <span class="hljs-comment">// 执行矩阵乘法</span><br>    <span class="hljs-built_in">matrix_multiply_cpu</span>(A, B, C);<br>    <br>    <span class="hljs-comment">// 计时结束</span><br>    <span class="hljs-keyword">auto</span> end = std::chrono::high_resolution_clock::<span class="hljs-built_in">now</span>();<br>    std::chrono::duration&lt;<span class="hljs-type">double</span>&gt; elapsed = end - start;<br>    <br>    std::cout &lt;&lt; <span class="hljs-string">&quot;CPU矩阵乘法耗时: &quot;</span> &lt;&lt; elapsed.<span class="hljs-built_in">count</span>() &lt;&lt; <span class="hljs-string">&quot; 秒&quot;</span> &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class="hljs-string">&quot;结果验证: C[0][0] = &quot;</span> &lt;&lt; C[<span class="hljs-number">0</span>] &lt;&lt; <span class="hljs-string">&quot; (预期值: &quot;</span> &lt;&lt; N * <span class="hljs-number">2.0f</span> &lt;&lt; <span class="hljs-string">&quot;)&quot;</span> &lt;&lt; std::endl;<br>    <br>    <span class="hljs-comment">// 释放内存</span><br>    <span class="hljs-keyword">delete</span>[] A;<br>    <span class="hljs-keyword">delete</span>[] B;<br>    <span class="hljs-keyword">delete</span>[] C;<br>    <br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="2-1D-Block构建运算"><a href="#2-1D-Block构建运算" class="headerlink" title="2. 1D Block构建运算"></a>2. 1D Block构建运算</h2><h3 id="2-1-CUDA代码里面的Thread是如何调用的"><a href="#2-1-CUDA代码里面的Thread是如何调用的" class="headerlink" title="2.1 CUDA代码里面的Thread是如何调用的"></a>2.1 CUDA代码里面的Thread是如何调用的</h3><p>在CUDA中，我们需要将计算任务分配给大量的线程。每个线程执行矩阵乘法的一部分计算。对于1D Block，我们将矩阵乘法的每个元素分配给一个线程。</p><p>CUDA核函数的调用形式如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cpp">kernel&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(parameters);<br></code></pre></td></tr></table></figure><p>其中：</p><ul><li><code>grid_size</code>：网格大小，即有多少个Block</li><li><code>block_size</code>：块大小，即每个Block中有多少个Thread</li></ul><p>在核函数内部，我们可以通过以下变量获取当前线程的ID：</p><ul><li><code>blockIdx.x</code>：当前Block在Grid中的索引</li><li><code>threadIdx.x</code>：当前Thread在Block中的索引</li><li><code>blockDim.x</code>：每个Block中的Thread数量</li></ul><h3 id="2-2-如何让不同的Thread与需要计算的数据匹配"><a href="#2-2-如何让不同的Thread与需要计算的数据匹配" class="headerlink" title="2.2 如何让不同的Thread与需要计算的数据匹配"></a>2.2 如何让不同的Thread与需要计算的数据匹配</h3><p>对于矩阵乘法<code>C = A * B</code>，我们需要为每个元素<code>C[i][j]</code>分配一个线程。线程ID与矩阵元素的对应关系如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-type">int</span> thread_id = blockIdx.x * blockDim.x + threadIdx.x;<br><span class="hljs-type">int</span> i = thread_id / N;<br><span class="hljs-type">int</span> j = thread_id % N;<br></code></pre></td></tr></table></figure><p>下面是完整的1D Block CUDA矩阵乘法实现：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;chrono&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cuda_runtime.h&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> N 1024</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> BLOCK_SIZE 256</span><br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">matrix_multiply_1d</span><span class="hljs-params">(<span class="hljs-type">float</span>* A, <span class="hljs-type">float</span>* B, <span class="hljs-type">float</span>* C, <span class="hljs-type">int</span> n)</span> </span>&#123;<br>    <span class="hljs-comment">// 计算当前线程的全局ID</span><br>    <span class="hljs-type">int</span> thread_id = blockIdx.x * blockDim.x + threadIdx.x;<br>    <br>    <span class="hljs-comment">// 计算对应的矩阵行和列</span><br>    <span class="hljs-type">int</span> i = thread_id / n;<br>    <span class="hljs-type">int</span> j = thread_id % n;<br>    <br>    <span class="hljs-comment">// 确保线程ID不超过矩阵大小</span><br>    <span class="hljs-keyword">if</span> (i &lt; n &amp;&amp; j &lt; n) &#123;<br>        <span class="hljs-type">float</span> sum = <span class="hljs-number">0.0f</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> k = <span class="hljs-number">0</span>; k &lt; n; ++k) &#123;<br>            sum += A[i * n + k] * B[k * n + j];<br>        &#125;<br>        C[i * n + j] = sum;<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-type">int</span> size = N * N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>    <br>    <span class="hljs-comment">// 分配主机内存</span><br>    <span class="hljs-type">float</span>* h_A = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N * N];<br>    <span class="hljs-type">float</span>* h_B = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N * N];<br>    <span class="hljs-type">float</span>* h_C = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N * N];<br>    <br>    <span class="hljs-comment">// 初始化数据</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N * N; ++i) &#123;<br>        h_A[i] = <span class="hljs-number">1.0f</span>;<br>        h_B[i] = <span class="hljs-number">2.0f</span>;<br>        h_C[i] = <span class="hljs-number">0.0f</span>;<br>    &#125;<br>    <br>    <span class="hljs-comment">// 分配设备内存</span><br>    <span class="hljs-type">float</span>* d_A, * d_B, * d_C;<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_A, size);<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_B, size);<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_C, size);<br>    <br>    <span class="hljs-comment">// 将数据从主机复制到设备</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(d_A, h_A, size, cudaMemcpyHostToDevice);<br>    <span class="hljs-built_in">cudaMemcpy</span>(d_B, h_B, size, cudaMemcpyHostToDevice);<br>    <br>    <span class="hljs-comment">// 计算Grid大小</span><br>    <span class="hljs-type">int</span> grid_size = (N * N + BLOCK_SIZE - <span class="hljs-number">1</span>) / BLOCK_SIZE;<br>    <br>    <span class="hljs-comment">// 计时开始</span><br>    <span class="hljs-keyword">auto</span> start = std::chrono::high_resolution_clock::<span class="hljs-built_in">now</span>();<br>    <br>    <span class="hljs-comment">// 启动核函数</span><br>    matrix_multiply_1d&lt;&lt;&lt;grid_size, BLOCK_SIZE&gt;&gt;&gt;(d_A, d_B, d_C, N);<br>    <span class="hljs-built_in">cudaDeviceSynchronize</span>(); <span class="hljs-comment">// 等待所有GPU线程完成</span><br>    <br>    <span class="hljs-comment">// 计时结束</span><br>    <span class="hljs-keyword">auto</span> end = std::chrono::high_resolution_clock::<span class="hljs-built_in">now</span>();<br>    std::chrono::duration&lt;<span class="hljs-type">double</span>&gt; elapsed = end - start;<br>    <br>    <span class="hljs-comment">// 将结果从设备复制到主机</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(h_C, d_C, size, cudaMemcpyDeviceToHost);<br>    <br>    std::cout &lt;&lt; <span class="hljs-string">&quot;1D Block GPU矩阵乘法耗时: &quot;</span> &lt;&lt; elapsed.<span class="hljs-built_in">count</span>() &lt;&lt; <span class="hljs-string">&quot; 秒&quot;</span> &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class="hljs-string">&quot;结果验证: C[0][0] = &quot;</span> &lt;&lt; h_C[<span class="hljs-number">0</span>] &lt;&lt; <span class="hljs-string">&quot; (预期值: &quot;</span> &lt;&lt; N * <span class="hljs-number">2.0f</span> &lt;&lt; <span class="hljs-string">&quot;)&quot;</span> &lt;&lt; std::endl;<br>    <br>    <span class="hljs-comment">// 释放内存</span><br>    <span class="hljs-keyword">delete</span>[] h_A;<br>    <span class="hljs-keyword">delete</span>[] h_B;<br>    <span class="hljs-keyword">delete</span>[] h_C;<br>    <span class="hljs-built_in">cudaFree</span>(d_A);<br>    <span class="hljs-built_in">cudaFree</span>(d_B);<br>    <span class="hljs-built_in">cudaFree</span>(d_C);<br>    <br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>编译命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">nvcc matrix_multiply_1d.cu -o matrix_multiply_1d<br></code></pre></td></tr></table></figure><h2 id="3-二维块（2D-Block）优化运算"><a href="#3-二维块（2D-Block）优化运算" class="headerlink" title="3. 二维块（2D Block）优化运算"></a>3. 二维块（2D Block）优化运算</h2><p>使用2D Block可以更好地利用GPU的内存访问模式，提高缓存命中率。在2D Block中，我们将矩阵的行和列分别映射到Block和Thread的二维索引上。</p><p>在2D Block中，我们需要使用以下变量获取当前线程的二维ID：</p><ul><li><code>blockIdx.x</code>, <code>blockIdx.y</code>：当前Block在Grid中的二维索引</li><li><code>threadIdx.x</code>, <code>threadIdx.y</code>：当前Thread在Block中的二维索引</li><li><code>blockDim.x</code>, <code>blockDim.y</code>：每个Block中的Thread数量（二维）</li></ul><p>线程ID与矩阵元素的对应关系如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-type">int</span> i = blockIdx.y * blockDim.y + threadIdx.y;<br><span class="hljs-type">int</span> j = blockIdx.x * blockDim.x + threadIdx.x;<br></code></pre></td></tr></table></figure><p>此外，我们还可以使用共享内存来缓存矩阵的局部块，减少全局内存访问次数，进一步提高性能。</p><p>下面是完整的2D Block CUDA矩阵乘法实现：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;chrono&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cuda_runtime.h&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> N 1024</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> BLOCK_SIZE 16</span><br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">matrix_multiply_2d</span><span class="hljs-params">(<span class="hljs-type">float</span>* A, <span class="hljs-type">float</span>* B, <span class="hljs-type">float</span>* C, <span class="hljs-type">int</span> n)</span> </span>&#123;<br>    <span class="hljs-comment">// 计算当前线程的二维索引</span><br>    <span class="hljs-type">int</span> i = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-type">int</span> j = blockIdx.x * blockDim.x + threadIdx.x;<br>    <br>    <span class="hljs-comment">// 共享内存用于缓存A和B的局部块</span><br>    __shared__ <span class="hljs-type">float</span> s_A[BLOCK_SIZE][BLOCK_SIZE];<br>    __shared__ <span class="hljs-type">float</span> s_B[BLOCK_SIZE][BLOCK_SIZE];<br>    <br>    <span class="hljs-type">float</span> sum = <span class="hljs-number">0.0f</span>;<br>    <br>    <span class="hljs-comment">// 循环处理所有需要的块</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> k_block = <span class="hljs-number">0</span>; k_block &lt; (n + BLOCK_SIZE - <span class="hljs-number">1</span>) / BLOCK_SIZE; ++k_block) &#123;<br>        <span class="hljs-comment">// 加载A的当前块到共享内存</span><br>        <span class="hljs-keyword">if</span> (i &lt; n &amp;&amp; (k_block * BLOCK_SIZE + threadIdx.x) &lt; n) &#123;<br>            s_A[threadIdx.y][threadIdx.x] = A[i * n + k_block * BLOCK_SIZE + threadIdx.x];<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            s_A[threadIdx.y][threadIdx.x] = <span class="hljs-number">0.0f</span>;<br>        &#125;<br>        <br>        <span class="hljs-comment">// 加载B的当前块到共享内存</span><br>        <span class="hljs-keyword">if</span> (j &lt; n &amp;&amp; (k_block * BLOCK_SIZE + threadIdx.y) &lt; n) &#123;<br>            s_B[threadIdx.y][threadIdx.x] = B[(k_block * BLOCK_SIZE + threadIdx.y) * n + j];<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            s_B[threadIdx.y][threadIdx.x] = <span class="hljs-number">0.0f</span>;<br>        &#125;<br>        <br>        <span class="hljs-comment">// 等待所有线程加载完成</span><br>        __syncthreads();<br>        <br>        <span class="hljs-comment">// 计算当前块的贡献</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> k = <span class="hljs-number">0</span>; k &lt; BLOCK_SIZE; ++k) &#123;<br>            sum += s_A[threadIdx.y][k] * s_B[k][threadIdx.x];<br>        &#125;<br>        <br>        <span class="hljs-comment">// 等待所有线程计算完成</span><br>        __syncthreads();<br>    &#125;<br>    <br>    <span class="hljs-comment">// 存储结果</span><br>    <span class="hljs-keyword">if</span> (i &lt; n &amp;&amp; j &lt; n) &#123;<br>        C[i * n + j] = sum;<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-type">int</span> size = N * N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>    <br>    <span class="hljs-comment">// 分配主机内存</span><br>    <span class="hljs-type">float</span>* h_A = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N * N];<br>    <span class="hljs-type">float</span>* h_B = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N * N];<br>    <span class="hljs-type">float</span>* h_C = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N * N];<br>    <br>    <span class="hljs-comment">// 初始化数据</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N * N; ++i) &#123;<br>        h_A[i] = <span class="hljs-number">1.0f</span>;<br>        h_B[i] = <span class="hljs-number">2.0f</span>;<br>        h_C[i] = <span class="hljs-number">0.0f</span>;<br>    &#125;<br>    <br>    <span class="hljs-comment">// 分配设备内存</span><br>    <span class="hljs-type">float</span>* d_A, * d_B, * d_C;<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_A, size);<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_B, size);<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_C, size);<br>    <br>    <span class="hljs-comment">// 将数据从主机复制到设备</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(d_A, h_A, size, cudaMemcpyHostToDevice);<br>    <span class="hljs-built_in">cudaMemcpy</span>(d_B, h_B, size, cudaMemcpyHostToDevice);<br>    <br>    <span class="hljs-comment">// 计算Grid和Block大小</span><br>    <span class="hljs-function">dim3 <span class="hljs-title">block_size</span><span class="hljs-params">(BLOCK_SIZE, BLOCK_SIZE)</span></span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">grid_size</span><span class="hljs-params">((N + block_size.x - <span class="hljs-number">1</span>) / block_size.x, (N + block_size.y - <span class="hljs-number">1</span>) / block_size.y)</span></span>;<br>    <br>    <span class="hljs-comment">// 计时开始</span><br>    <span class="hljs-keyword">auto</span> start = std::chrono::high_resolution_clock::<span class="hljs-built_in">now</span>();<br>    <br>    <span class="hljs-comment">// 启动核函数</span><br>    matrix_multiply_2d&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_A, d_B, d_C, N);<br>    <span class="hljs-built_in">cudaDeviceSynchronize</span>(); <span class="hljs-comment">// 等待所有GPU线程完成</span><br>    <br>    <span class="hljs-comment">// 计时结束</span><br>    <span class="hljs-keyword">auto</span> end = std::chrono::high_resolution_clock::<span class="hljs-built_in">now</span>();<br>    std::chrono::duration&lt;<span class="hljs-type">double</span>&gt; elapsed = end - start;<br>    <br>    <span class="hljs-comment">// 将结果从设备复制到主机</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(h_C, d_C, size, cudaMemcpyDeviceToHost);<br>    <br>    std::cout &lt;&lt; <span class="hljs-string">&quot;2D Block GPU矩阵乘法耗时: &quot;</span> &lt;&lt; elapsed.<span class="hljs-built_in">count</span>() &lt;&lt; <span class="hljs-string">&quot; 秒&quot;</span> &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class="hljs-string">&quot;结果验证: C[0][0] = &quot;</span> &lt;&lt; h_C[<span class="hljs-number">0</span>] &lt;&lt; <span class="hljs-string">&quot; (预期值: &quot;</span> &lt;&lt; N * <span class="hljs-number">2.0f</span> &lt;&lt; <span class="hljs-string">&quot;)&quot;</span> &lt;&lt; std::endl;<br>    <br>    <span class="hljs-comment">// 释放内存</span><br>    <span class="hljs-keyword">delete</span>[] h_A;<br>    <span class="hljs-keyword">delete</span>[] h_B;<br>    <span class="hljs-keyword">delete</span>[] h_C;<br>    <span class="hljs-built_in">cudaFree</span>(d_A);<br>    <span class="hljs-built_in">cudaFree</span>(d_B);<br>    <span class="hljs-built_in">cudaFree</span>(d_C);<br>    <br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>编译命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">nvcc matrix_multiply_2d.cu -o matrix_multiply_2d<br></code></pre></td></tr></table></figure><h2 id="4-CUBLAS函数调用"><a href="#4-CUBLAS函数调用" class="headerlink" title="4. CUBLAS函数调用"></a>4. CUBLAS函数调用</h2><p>CUBLAS（CUDA Basic Linear Algebra Subprograms）是NVIDIA提供的高性能线性代数库，可以进一步提高矩阵运算的性能。</p><p>使用CUBLAS进行矩阵乘法需要注意以下几点：</p><ul><li>CUBLAS使用列优先存储格式（Fortran风格），而我们通常使用行优先存储格式（C风格）</li><li>需要设置矩阵的转置标志</li><li>矩阵乘法的形式为<code>C = alpha * A * B + beta * C</code></li></ul><p>下面是完整的CUBLAS矩阵乘法实现：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;chrono&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cuda_runtime.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cublas_v2.h&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> N 1024</span><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-type">int</span> size = N * N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>    <br>    <span class="hljs-comment">// 分配主机内存</span><br>    <span class="hljs-type">float</span>* h_A = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N * N];<br>    <span class="hljs-type">float</span>* h_B = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N * N];<br>    <span class="hljs-type">float</span>* h_C = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[N * N];<br>    <br>    <span class="hljs-comment">// 初始化数据</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N * N; ++i) &#123;<br>        h_A[i] = <span class="hljs-number">1.0f</span>;<br>        h_B[i] = <span class="hljs-number">2.0f</span>;<br>        h_C[i] = <span class="hljs-number">0.0f</span>;<br>    &#125;<br>    <br>    <span class="hljs-comment">// 分配设备内存</span><br>    <span class="hljs-type">float</span>* d_A, * d_B, * d_C;<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_A, size);<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_B, size);<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span>**)&amp;d_C, size);<br>    <br>    <span class="hljs-comment">// 将数据从主机复制到设备</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(d_A, h_A, size, cudaMemcpyHostToDevice);<br>    <span class="hljs-built_in">cudaMemcpy</span>(d_B, h_B, size, cudaMemcpyHostToDevice);<br>    <br>    <span class="hljs-comment">// 初始化CUBLAS句柄</span><br>    cublasHandle_t handle;<br>    <span class="hljs-built_in">cublasCreate</span>(&amp;handle);<br>    <br>    <span class="hljs-comment">// 设置矩阵乘法参数</span><br>    <span class="hljs-type">const</span> <span class="hljs-type">float</span> alpha = <span class="hljs-number">1.0f</span>;<br>    <span class="hljs-type">const</span> <span class="hljs-type">float</span> beta = <span class="hljs-number">0.0f</span>;<br>    <br>    <span class="hljs-comment">// 计时开始</span><br>    <span class="hljs-keyword">auto</span> start = std::chrono::high_resolution_clock::<span class="hljs-built_in">now</span>();<br>    <br>    <span class="hljs-comment">// 执行矩阵乘法：C = alpha * A^T * B^T + beta * C</span><br>    <span class="hljs-comment">// 注意：由于CUBLAS使用列优先，我们需要转置矩阵</span><br>    <span class="hljs-built_in">cublasSgemm</span>(handle, <br>                CUBLAS_OP_N, CUBLAS_OP_N,  <span class="hljs-comment">// A和B都不转置</span><br>                N, N, N,                  <span class="hljs-comment">// C的行数，C的列数，A的列数/B的行数</span><br>                &amp;alpha,                   <span class="hljs-comment">// 缩放因子alpha</span><br>                d_A, N,                   <span class="hljs-comment">// 矩阵A，A的领先维度</span><br>                d_B, N,                   <span class="hljs-comment">// 矩阵B，B的领先维度</span><br>                &amp;beta,                    <span class="hljs-comment">// 缩放因子beta</span><br>                d_C, N);                  <span class="hljs-comment">// 矩阵C，C的领先维度</span><br>    <br>    <span class="hljs-built_in">cudaDeviceSynchronize</span>(); <span class="hljs-comment">// 等待所有GPU操作完成</span><br>    <br>    <span class="hljs-comment">// 计时结束</span><br>    <span class="hljs-keyword">auto</span> end = std::chrono::high_resolution_clock::<span class="hljs-built_in">now</span>();<br>    std::chrono::duration&lt;<span class="hljs-type">double</span>&gt; elapsed = end - start;<br>    <br>    <span class="hljs-comment">// 将结果从设备复制到主机</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(h_C, d_C, size, cudaMemcpyDeviceToHost);<br>    <br>    std::cout &lt;&lt; <span class="hljs-string">&quot;CUBLAS矩阵乘法耗时: &quot;</span> &lt;&lt; elapsed.<span class="hljs-built_in">count</span>() &lt;&lt; <span class="hljs-string">&quot; 秒&quot;</span> &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class="hljs-string">&quot;结果验证: C[0][0] = &quot;</span> &lt;&lt; h_C[<span class="hljs-number">0</span>] &lt;&lt; <span class="hljs-string">&quot; (预期值: &quot;</span> &lt;&lt; N * <span class="hljs-number">2.0f</span> &lt;&lt; <span class="hljs-string">&quot;)&quot;</span> &lt;&lt; std::endl;<br>    <br>    <span class="hljs-comment">// 释放资源</span><br>    <span class="hljs-keyword">delete</span>[] h_A;<br>    <span class="hljs-keyword">delete</span>[] h_B;<br>    <span class="hljs-keyword">delete</span>[] h_C;<br>    <span class="hljs-built_in">cudaFree</span>(d_A);<br>    <span class="hljs-built_in">cudaFree</span>(d_B);<br>    <span class="hljs-built_in">cudaFree</span>(d_C);<br>    <span class="hljs-built_in">cublasDestroy</span>(handle);<br>    <br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>编译命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">nvcc matrix_multiply_cublas.cu -o matrix_multiply_cublas -lcublas<br></code></pre></td></tr></table></figure><h2 id="5-性能对比"><a href="#5-性能对比" class="headerlink" title="5. 性能对比"></a>5. 性能对比</h2><p>在相同硬件条件下，我们可以得到类似以下的性能对比结果：</p><table><thead><tr><th>实现方式</th><th>耗时（秒）</th><th>加速比</th></tr></thead><tbody><tr><td>CPU</td><td>~1.0</td><td>1x</td></tr><tr><td>1D Block</td><td>~0.1</td><td>10x</td></tr><tr><td>2D Block</td><td>~0.02</td><td>50x</td></tr><tr><td>CUBLAS</td><td>~0.005</td><td>200x</td></tr></tbody></table><p>需要注意的是，实际性能会受到硬件配置、矩阵大小等因素的影响。</p><h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h2><p>本文介绍了CUDA矩阵乘法的三种实现方式：</p><ol><li><strong>1D Block</strong>：将每个矩阵元素分配给一个线程，简单直观但性能一般</li><li><strong>2D Block</strong>：使用二维线程块和共享内存，提高缓存命中率，性能较好</li><li><strong>CUBLAS</strong>：使用NVIDIA优化的线性代数库，性能最佳</li></ol><p>通过合理利用GPU的并行计算能力，我们可以将矩阵乘法的性能提高几个数量级。在实际应用中，建议优先使用CUBLAS等优化库，以获得最佳性能。</p>]]></content>
    
    
    <categories>
      
      <category>GPU</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>31_研究矩阵的特征值和特征向量</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/31_%E7%A0%94%E7%A9%B6%E7%9F%A9%E9%98%B5%E7%9A%84%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/31_%E7%A0%94%E7%A9%B6%E7%9F%A9%E9%98%B5%E7%9A%84%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>30_线性映射</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/30_%E7%BA%BF%E6%80%A7%E6%98%A0%E5%B0%84/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/30_%E7%BA%BF%E6%80%A7%E6%98%A0%E5%B0%84/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>29_齐次矩阵</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/29_%E9%BD%90%E6%AC%A1%E7%9F%A9%E9%98%B5/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/29_%E9%BD%90%E6%AC%A1%E7%9F%A9%E9%98%B5/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>28_SVD_QR_LU_SVD的几何意义</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/28_SVD_QR_LU_SVD%E7%9A%84%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/28_SVD_QR_LU_SVD%E7%9A%84%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>27_对角化_特征向量正交性_实对称矩阵的特征值</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/27_%E5%AF%B9%E8%A7%92%E5%8C%96_%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E6%AD%A3%E4%BA%A4%E6%80%A7_%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E7%89%B9%E5%BE%81%E5%80%BC/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/27_%E5%AF%B9%E8%A7%92%E5%8C%96_%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E6%AD%A3%E4%BA%A4%E6%80%A7_%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E7%89%B9%E5%BE%81%E5%80%BC/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>26_线性代数的作用_大数据的高维问题</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/26_%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%9A%84%E4%BD%9C%E7%94%A8_%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84%E9%AB%98%E7%BB%B4%E9%97%AE%E9%A2%98/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/26_%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%9A%84%E4%BD%9C%E7%94%A8_%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84%E9%AB%98%E7%BB%B4%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>25_如何理解克拉默法则</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/25_%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%85%8B%E6%8B%89%E9%BB%98%E6%B3%95%E5%88%99/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/25_%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%85%8B%E6%8B%89%E9%BB%98%E6%B3%95%E5%88%99/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>24_解空间的基和方程组的基础解系</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/24_%E8%A7%A3%E7%A9%BA%E9%97%B4%E7%9A%84%E5%9F%BA%E5%92%8C%E6%96%B9%E7%A8%8B%E7%BB%84%E7%9A%84%E5%9F%BA%E7%A1%80%E8%A7%A3%E7%B3%BB/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/24_%E8%A7%A3%E7%A9%BA%E9%97%B4%E7%9A%84%E5%9F%BA%E5%92%8C%E6%96%B9%E7%A8%8B%E7%BB%84%E7%9A%84%E5%9F%BA%E7%A1%80%E8%A7%A3%E7%B3%BB/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>23_通俗的解释SVD奇异值分解及作用</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/23_%E9%80%9A%E4%BF%97%E7%9A%84%E8%A7%A3%E9%87%8ASVD%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3%E5%8F%8A%E4%BD%9C%E7%94%A8/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/23_%E9%80%9A%E4%BF%97%E7%9A%84%E8%A7%A3%E9%87%8ASVD%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3%E5%8F%8A%E4%BD%9C%E7%94%A8/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>22_线性代数的核心思想</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/22_%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/22_%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>21_通俗理解矩阵的秩_数学意义</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/21_%E9%80%9A%E4%BF%97%E7%90%86%E8%A7%A3%E7%9F%A9%E9%98%B5%E7%9A%84%E7%A7%A9_%E6%95%B0%E5%AD%A6%E6%84%8F%E4%B9%89/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/21_%E9%80%9A%E4%BF%97%E7%90%86%E8%A7%A3%E7%9F%A9%E9%98%B5%E7%9A%84%E7%A7%A9_%E6%95%B0%E5%AD%A6%E6%84%8F%E4%B9%89/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>20_Jordan标准型的本质</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/20_Jordan%E6%A0%87%E5%87%86%E5%9E%8B%E7%9A%84%E6%9C%AC%E8%B4%A8/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/20_Jordan%E6%A0%87%E5%87%86%E5%9E%8B%E7%9A%84%E6%9C%AC%E8%B4%A8/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>19_线性代数中的线性相关或无关</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/19_%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3%E6%88%96%E6%97%A0%E5%85%B3/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/19_%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3%E6%88%96%E6%97%A0%E5%85%B3/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>18_基础解系_零空间</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/18_%E5%9F%BA%E7%A1%80%E8%A7%A3%E7%B3%BB_%E9%9B%B6%E7%A9%BA%E9%97%B4/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/18_%E5%9F%BA%E7%A1%80%E8%A7%A3%E7%B3%BB_%E9%9B%B6%E7%A9%BA%E9%97%B4/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>17_</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/17_/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/17_/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>16_矩阵行秩_列秩_最大非零子式_矩阵秩几何意义</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/16_%E7%9F%A9%E9%98%B5%E8%A1%8C%E7%A7%A9_%E5%88%97%E7%A7%A9_%E6%9C%80%E5%A4%A7%E9%9D%9E%E9%9B%B6%E5%AD%90%E5%BC%8F_%E7%9F%A9%E9%98%B5%E7%A7%A9%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/16_%E7%9F%A9%E9%98%B5%E8%A1%8C%E7%A7%A9_%E5%88%97%E7%A7%A9_%E6%9C%80%E5%A4%A7%E9%9D%9E%E9%9B%B6%E5%AD%90%E5%BC%8F_%E7%9F%A9%E9%98%B5%E7%A7%A9%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>15_特征值和特征向量的几何含义</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/15_%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E7%9A%84%E5%87%A0%E4%BD%95%E5%90%AB%E4%B9%89/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/15_%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E7%9A%84%E5%87%A0%E4%BD%95%E5%90%AB%E4%B9%89/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>14_矩阵的秩</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/14_%E7%9F%A9%E9%98%B5%E7%9A%84%E7%A7%A9/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/14_%E7%9F%A9%E9%98%B5%E7%9A%84%E7%A7%A9/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>13_矩阵等价_向量组等价</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/13_%E7%9F%A9%E9%98%B5%E7%AD%89%E4%BB%B7_%E5%90%91%E9%87%8F%E7%BB%84%E7%AD%89%E4%BB%B7/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/13_%E7%9F%A9%E9%98%B5%E7%AD%89%E4%BB%B7_%E5%90%91%E9%87%8F%E7%BB%84%E7%AD%89%E4%BB%B7/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>12_方阵特征分解_奇异值分解</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/12_%E6%96%B9%E9%98%B5%E7%89%B9%E5%BE%81%E5%88%86%E8%A7%A3_%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/12_%E6%96%B9%E9%98%B5%E7%89%B9%E5%BE%81%E5%88%86%E8%A7%A3_%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>11_本质_子空间和仿射子空间</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/11_%E6%9C%AC%E8%B4%A8_%E5%AD%90%E7%A9%BA%E9%97%B4%E5%92%8C%E4%BB%BF%E5%B0%84%E5%AD%90%E7%A9%BA%E9%97%B4/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/11_%E6%9C%AC%E8%B4%A8_%E5%AD%90%E7%A9%BA%E9%97%B4%E5%92%8C%E4%BB%BF%E5%B0%84%E5%AD%90%E7%A9%BA%E9%97%B4/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>10_最小二乘法_广义_加权_正则化</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/10_%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95_%E5%B9%BF%E4%B9%89_%E5%8A%A0%E6%9D%83_%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/10_%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95_%E5%B9%BF%E4%B9%89_%E5%8A%A0%E6%9D%83_%E6%AD%A3%E5%88%99%E5%8C%96/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>09_伴随算子_自伴算子_正规算子_二维旋转矩阵</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/09_%E4%BC%B4%E9%9A%8F%E7%AE%97%E5%AD%90_%E8%87%AA%E4%BC%B4%E7%AE%97%E5%AD%90_%E6%AD%A3%E8%A7%84%E7%AE%97%E5%AD%90_%E4%BA%8C%E7%BB%B4%E6%97%8B%E8%BD%AC%E7%9F%A9%E9%98%B5/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/09_%E4%BC%B4%E9%9A%8F%E7%AE%97%E5%AD%90_%E8%87%AA%E4%BC%B4%E7%AE%97%E5%AD%90_%E6%AD%A3%E8%A7%84%E7%AE%97%E5%AD%90_%E4%BA%8C%E7%BB%B4%E6%97%8B%E8%BD%AC%E7%9F%A9%E9%98%B5/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>08_子空间_基</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/08_%E5%AD%90%E7%A9%BA%E9%97%B4_%E5%9F%BA/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/08_%E5%AD%90%E7%A9%BA%E9%97%B4_%E5%9F%BA/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>07_宏观掌握线性代数_对角化_张量</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/07_%E5%AE%8F%E8%A7%82%E6%8E%8C%E6%8F%A1%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0_%E5%AF%B9%E8%A7%92%E5%8C%96_%E5%BC%A0%E9%87%8F/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/07_%E5%AE%8F%E8%A7%82%E6%8E%8C%E6%8F%A1%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0_%E5%AF%B9%E8%A7%92%E5%8C%96_%E5%BC%A0%E9%87%8F/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>06_矩阵的正定及半正定</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/06_%E7%9F%A9%E9%98%B5%E7%9A%84%E6%AD%A3%E5%AE%9A%E5%8F%8A%E5%8D%8A%E6%AD%A3%E5%AE%9A/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/06_%E7%9F%A9%E9%98%B5%E7%9A%84%E6%AD%A3%E5%AE%9A%E5%8F%8A%E5%8D%8A%E6%AD%A3%E5%AE%9A/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>05_二次型</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/05_%E4%BA%8C%E6%AC%A1%E5%9E%8B/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/05_%E4%BA%8C%E6%AC%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>04_特征值之和_矩阵的迹</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/04_%E7%89%B9%E5%BE%81%E5%80%BC%E4%B9%8B%E5%92%8C_%E7%9F%A9%E9%98%B5%E7%9A%84%E8%BF%B9/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/04_%E7%89%B9%E5%BE%81%E5%80%BC%E4%B9%8B%E5%92%8C_%E7%9F%A9%E9%98%B5%E7%9A%84%E8%BF%B9/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>03_奇异值_特征值</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/03_%E5%A5%87%E5%BC%82%E5%80%BC_%E7%89%B9%E5%BE%81%E5%80%BC/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/03_%E5%A5%87%E5%BC%82%E5%80%BC_%E7%89%B9%E5%BE%81%E5%80%BC/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>02_转置_求逆</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/02_%E8%BD%AC%E7%BD%AE_%E6%B1%82%E9%80%86/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/02_%E8%BD%AC%E7%BD%AE_%E6%B1%82%E9%80%86/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>01_矩阵_向量组_线性方程组</title>
    <link href="/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/01_%E7%9F%A9%E9%98%B5_%E5%90%91%E9%87%8F%E7%BB%84_%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/"/>
    <url>/2025/12/28/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/01_%E7%9F%A9%E9%98%B5_%E5%90%91%E9%87%8F%E7%BB%84_%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>线性代数</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>海森矩阵</title>
    <link href="/2025/12/28/%E6%95%B0%E5%AD%A6%E7%AC%94%E8%AE%B0/%E6%8F%92%E5%80%BC%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    <url>/2025/12/28/%E6%95%B0%E5%AD%A6%E7%AC%94%E8%AE%B0/%E6%8F%92%E5%80%BC%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>数学笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>最小二乘法</title>
    <link href="/2025/12/28/%E6%95%B0%E5%AD%A6%E7%AC%94%E8%AE%B0/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/"/>
    <url>/2025/12/28/%E6%95%B0%E5%AD%A6%E7%AC%94%E8%AE%B0/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>数学笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>矩阵转置</title>
    <link href="/2025/12/28/%E6%95%B0%E5%AD%A6%E7%AC%94%E8%AE%B0/%E7%9F%A9%E9%98%B5%E8%BD%AC%E7%BD%AE/"/>
    <url>/2025/12/28/%E6%95%B0%E5%AD%A6%E7%AC%94%E8%AE%B0/%E7%9F%A9%E9%98%B5%E8%BD%AC%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<h3 id="转置的代数定义与基本性质"><a href="#转置的代数定义与基本性质" class="headerlink" title="转置的代数定义与基本性质"></a>转置的代数定义与基本性质</h3>]]></content>
    
    
    <categories>
      
      <category>数学笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>海森矩阵</title>
    <link href="/2025/12/28/%E6%95%B0%E5%AD%A6%E7%AC%94%E8%AE%B0/%E6%B5%B7%E6%A3%AE%E7%9F%A9%E9%98%B5/"/>
    <url>/2025/12/28/%E6%95%B0%E5%AD%A6%E7%AC%94%E8%AE%B0/%E6%B5%B7%E6%A3%AE%E7%9F%A9%E9%98%B5/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>数学笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>雅克比矩阵</title>
    <link href="/2025/12/28/%E6%95%B0%E5%AD%A6%E7%AC%94%E8%AE%B0/%E9%9B%85%E5%85%8B%E6%AF%94%E7%9F%A9%E9%98%B5/"/>
    <url>/2025/12/28/%E6%95%B0%E5%AD%A6%E7%AC%94%E8%AE%B0/%E9%9B%85%E5%85%8B%E6%AF%94%E7%9F%A9%E9%98%B5/</url>
    
    <content type="html"><![CDATA[<h1 id="雅可比矩阵（Jacobian-Matrix）"><a href="#雅可比矩阵（Jacobian-Matrix）" class="headerlink" title="雅可比矩阵（Jacobian Matrix）"></a>雅可比矩阵（Jacobian Matrix）</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>本文介绍雅可比矩阵的定义、基本性质，并重点讨论其在机械臂学与机器学习中的常见应用。文末给出一个使用 Eigen 库计算雅可比矩阵的 C++ 示例，并提供运行说明。</p><h2 id="1-数学定义与作用"><a href="#1-数学定义与作用" class="headerlink" title="1. 数学定义与作用"></a>1. 数学定义与作用</h2><p>设 $\mathbf{f}:\mathbb{R}^n\to\mathbb{R}^m$，$\mathbf{f}(\mathbf{x})&#x3D;[f_1(\mathbf{x}),\dots,f_m(\mathbf{x})]^T$，$\mathbf{x}&#x3D;[x_1,\dots,x_n]^T$。雅可比矩阵定义为：</p><p>$$<br>J(\mathbf{x})&#x3D;\frac{\partial\mathbf{f}}{\partial\mathbf{x}}&#x3D;\begin{bmatrix}<br>\dfrac{\partial f_1}{\partial x_1} &amp; \cdots &amp; \dfrac{\partial f_1}{\partial x_n} \<br>\vdots &amp; \ddots &amp; \vdots \<br>\dfrac{\partial f_m}{\partial x_1} &amp; \cdots &amp; \dfrac{\partial f_m}{\partial x_n}<br>\end{bmatrix}.<br>$$</p><p>雅可比矩阵是局部线性近似的核心：当 $\Delta\mathbf{x}$ 足够小时，</p><p>$$<br>\mathbf{f}(\mathbf{x}+\Delta\mathbf{x})\approx \mathbf{f}(\mathbf{x}) + J(\mathbf{x}),\Delta\mathbf{x}.<br>$$</p><p>常见用途：坐标变换的微分、非线性方程求解（牛顿法）、最优化（构造 Gauss–Newton 的近似 Hessian）、灵敏度分析与不确定性传播等。</p><h2 id="1-1-几何直观解释"><a href="#1-1-几何直观解释" class="headerlink" title="1.1 几何直观解释"></a>1.1 几何直观解释</h2><p>雅可比矩阵可以被视为非线性变换的局部”变形率”矩阵，提供了从输入空间到输出空间的线性近似映射。从几何角度理解：</p><ul><li><strong>向量变换</strong>：雅可比矩阵的列向量代表输入空间中标准基向量（坐标轴方向）在输出空间中的拉伸&#x2F;旋转方向。</li><li><strong>面积&#x2F;体积变化</strong>：雅可比行列式（对于方阵）表示输入空间中微小区域在经过非线性变换后，其面积&#x2F;体积的缩放因子。</li><li><strong>方向导数</strong>：雅可比矩阵与一个方向向量点积，给出函数在该方向上的方向导数。</li></ul><p>举个简单例子：考虑极坐标到直角坐标的变换 $(x,y)&#x3D;f(r,\theta)&#x3D;(r\cos\theta, r\sin\theta)$，其雅可比矩阵为：</p><p>$$<br>J(r,\theta)&#x3D;\begin{bmatrix}<br>\cos\theta &amp; -r\sin\theta \<br>\sin\theta &amp; r\cos\theta<br>\end{bmatrix}<br>$$</p><p>这里第一列表示半径方向微小变化 $dr$ 在 $x$ 和 $y$ 方向的投影，第二列表示角度方向微小变化 $d\theta$ 在 $x$ 和 $y$ 方向的切线投影。雅可比行列式为 $r$，表示极坐标下的微小面积元 $dr d\theta$ 变换为直角坐标系下的面积元 $r dr d\theta$，这与极坐标积分中的面积元一致。</p><h2 id="1-2-雅可比行列式"><a href="#1-2-雅可比行列式" class="headerlink" title="1.2 雅可比行列式"></a>1.2 雅可比行列式</h2><p>当雅可比矩阵为方阵（即 $m&#x3D;n$）时，其行列式称为<strong>雅可比行列式</strong>（Jacobian Determinant），记为 $\det J(\mathbf{x})$ 或 $\frac{\partial(f_1,\ldots,f_n)}{\partial(x_1,\ldots,x_n)}$。雅可比行列式具有重要的几何和物理意义：</p><ul><li><p><strong>体积缩放因子</strong>：如前所述，对于输入空间中的微小区域，雅可比行列式的绝对值表示该区域在非线性变换后的体积缩放比例。</p></li><li><p><strong>可逆性条件</strong>：根据逆函数定理，若 $J(\mathbf{x_0})\neq 0$，则函数 $\mathbf{f}$ 在点 $\mathbf{x_0}$ 的邻域内是局部可逆的。</p></li><li><p><strong>坐标变换</strong>：在多重积分中，雅可比行列式用于变量替换：</p><p>$$\int_{f(U)} g(\mathbf{y}) d\mathbf{y} &#x3D; \int_U g(\mathbf{f}(\mathbf{x})) \left|\det J(\mathbf{x})\right| d\mathbf{x}$$</p><p>其中 $U$ 是输入空间中的区域，$f(U)$ 是其在输出空间中的像。</p></li><li><p><strong>物理应用</strong>：在流体力学中，雅可比行列式与流体的压缩性相关；在热力学中，用于描述状态变量之间的关系。</p></li></ul><h2 id="2-在机械臂中的作用"><a href="#2-在机械臂中的作用" class="headerlink" title="2. 在机械臂中的作用"></a>2. 在机械臂中的作用</h2><p>机械臂的正运动学映射常写为 $\mathbf{x}&#x3D;\mathbf{f}(\mathbf{q})$，其中 $\mathbf{q}\in\mathbb{R}^n$ 为关节变量，$\mathbf{x}\in\mathbb{R}^m$ 为末端位姿（位置与姿态）。雅可比矩阵在机器人学中具有下列重要作用：</p><ul><li><p>速度映射：</p><p>  $$\dot{\mathbf{x}} &#x3D; J(\mathbf{q}),\dot{\mathbf{q}}$$</p><p>  表示关节速度到末端速度的线性关系，便于轨迹跟踪与速度规划。</p></li><li><p>力&#x2F;力矩变换（虚功守恒）：</p><p>  $$\boldsymbol{\tau} &#x3D; J(\mathbf{q})^T,\mathbf{F}$$</p><p>  将末端受力映射到关节力矩，用于力控制和阻抗控制设计。</p></li><li><p>奇异性分析：若 $J$ 在某配置处秩减少（例如行列式为 0），机器人在该配置可能失去某些方向的运动能力或需要无限大的关节速度来实现某方向的末端速度。奇异点检测与规避对运动规划与控制至关重要。</p></li><li><p>逆运动学的增量求解：基于线性化可用伪逆更新关节变量：</p><p>  $$\Delta\mathbf{q} &#x3D; J(\mathbf{q})^+,\Delta\mathbf{x}$$</p><p>  这里 $J^+$ 是 Moore–Penrose 伪逆，适用于冗余或欠定&#x2F;超定情况。</p></li></ul><h3 id="2-1-示例：平面-2-link-机械臂雅可比（推导）"><a href="#2-1-示例：平面-2-link-机械臂雅可比（推导）" class="headerlink" title="2.1 示例：平面 2-link 机械臂雅可比（推导）"></a>2.1 示例：平面 2-link 机械臂雅可比（推导）</h3><p>考虑长度分别为 $l_1,l_2$，关节角为 $\theta_1,\theta_2$ 的平面机械臂，末端位置为：</p><p>$$<br>x &#x3D; l_1\cos\theta_1 + l_2\cos(\theta_1+\theta_2),\<br>y &#x3D; l_1\sin\theta_1 + l_2\sin(\theta_1+\theta_2).<br>$$</p><p>则位置部分的雅可比为：</p><p>$$<br>J_p(\theta)&#x3D;\begin{bmatrix}<br>-l_1\sin\theta_1 - l_2\sin(\theta_1+\theta_2) &amp; -l_2\sin(\theta_1+\theta_2) \<br>l_1\cos\theta_1 + l_2\cos(\theta_1+\theta_2) &amp; l_2\cos(\theta_1+\theta_2)<br>\end{bmatrix}.<br>$$</p><p>该矩阵用于把关节速度映射为末端线速度，并可据此分析奇异配置（例如当两连杆伸直或折叠时）。</p><h3 id="2-2-姿态雅可比与完整雅可比矩阵"><a href="#2-2-姿态雅可比与完整雅可比矩阵" class="headerlink" title="2.2 姿态雅可比与完整雅可比矩阵"></a>2.2 姿态雅可比与完整雅可比矩阵</h3><p>在机器人学中，机械臂的末端位姿包括位置和姿态两部分，因此完整的雅可比矩阵也包含位置雅可比和姿态雅可比两个部分：</p><p>$$<br>J(\mathbf{q}) &#x3D; \begin{bmatrix}<br>J_p(\mathbf{q}) \<br>J_o(\mathbf{q})<br>\end{bmatrix}<br>$$</p><p>其中：</p><ul><li>$J_p(\mathbf{q}) \in \mathbb{R}^{3\times n}$ 是位置雅可比，将关节速度映射到末端执行器的线速度；</li><li>$J_o(\mathbf{q}) \in \mathbb{R}^{3\times n}$ 是姿态雅可比，将关节速度映射到末端执行器的角速度。</li></ul><p>对于平面机械臂，姿态通常由单个角度 $\phi$ 表示，因此姿态雅可比为 $J_o(\mathbf{q}) \in \mathbb{R}^{1\times n}$。以平面2-link机械臂为例，末端姿态角 $\phi &#x3D; \theta_1 + \theta_2$，其姿态雅可比为：</p><p>$$<br>J_o(\theta) &#x3D; \begin{bmatrix} 1 &amp; 1 \end{bmatrix}<br>$$</p><p>这表示两个关节的角速度都会直接影响末端的姿态角速度，且影响系数均为1。</p><p>完整的平面2-link机械臂雅可比矩阵为：</p><p>$$<br>J(\theta) &#x3D; \begin{bmatrix}<br>J_p(\theta) \<br>J_o(\theta)<br>\end{bmatrix} &#x3D; \begin{bmatrix}<br>-l_1\sin\theta_1 - l_2\sin(\theta_1+\theta_2) &amp; -l_2\sin(\theta_1+\theta_2) \<br>l_1\cos\theta_1 + l_2\cos(\theta_1+\theta_2) &amp; l_2\cos(\theta_1+\theta_2) \<br>1 &amp; 1<br>\end{bmatrix}<br>$$</p><h3 id="2-3-雅可比矩阵的计算方法（机器人学）"><a href="#2-3-雅可比矩阵的计算方法（机器人学）" class="headerlink" title="2.3 雅可比矩阵的计算方法（机器人学）"></a>2.3 雅可比矩阵的计算方法（机器人学）</h3><p>机器人学中计算雅可比矩阵主要有两种方法：</p><ol><li><p><strong>几何法（矢量法）</strong>：基于刚体运动学，通过分析每个关节运动对末端位姿的影响来构建雅可比矩阵。对于旋转关节 $i$，其对末端位置的贡献是一个切向量，对姿态的贡献是旋转轴方向；对于移动关节，其对末端位置的贡献是关节轴线方向，对姿态无贡献。</p></li><li><p><strong>微分变换法</strong>：基于齐次变换矩阵的微分，通过对正运动学的齐次变换矩阵求导来计算雅可比矩阵。这种方法更系统，便于计算机实现。</p></li></ol><p>两种方法各有优缺点：几何法直观易懂，适合简单机器人；微分变换法更通用，适合复杂机器人结构的自动计算。</p><h2 id="3-在机器学习中的作用"><a href="#3-在机器学习中的作用" class="headerlink" title="3. 在机器学习中的作用"></a>3. 在机器学习中的作用</h2><p>雅可比矩阵在机器学习中的应用很广：</p><ul><li><p>反向传播（Backpropagation）：神经网络层的局部映射可用雅可比来表征，实际计算中经常需要 Jacobian-向量积或向量-Jacobian 积以避免构造完整矩阵。</p></li><li><p>灵敏度分析与对抗样本：评估输入微小扰动对输出（或损失）的影响，雅可比能给出每个输入维度的局部敏感度。</p></li><li><p>可逆模型与概率密度变换：可逆变换模型（如 normalizing flows）需要快速计算变换的雅可比行列式以便进行概率密度变换：</p><p>  $$p_X(\mathbf{x}) &#x3D; p_Z(\mathbf{z}) \left|\det\frac{\partial\mathbf{z}}{\partial\mathbf{x}}\right|$$</p><p>  设计可高效计算行列式的层（如三角雅可比）是流模型的关键。</p></li><li><p>二阶优化与 Gauss–Newton：最小二乘问题中常构造 $J^T J$ 作为近似 Hessian，用于求解参数更新方向。</p></li></ul><h3 id="3-1-机器学习中的具体应用案例"><a href="#3-1-机器学习中的具体应用案例" class="headerlink" title="3.1 机器学习中的具体应用案例"></a>3.1 机器学习中的具体应用案例</h3><h4 id="3-1-1-生成对抗网络（GAN）的稳定性分析"><a href="#3-1-1-生成对抗网络（GAN）的稳定性分析" class="headerlink" title="3.1.1 生成对抗网络（GAN）的稳定性分析"></a>3.1.1 生成对抗网络（GAN）的稳定性分析</h4><p>在生成对抗网络中，生成器和判别器的训练过程是一个极小极大博弈问题。雅可比矩阵用于分析训练过程的稳定性：</p><ul><li><strong>谱归一化</strong>：通过计算生成器权重矩阵的最大奇异值（雅可比矩阵的谱范数）来正则化模型，防止梯度爆炸，提高训练稳定性。</li><li><strong>梯度惩罚</strong>：Wasserstein GAN (WGAN-GP) 中，通过计算判别器在真实样本和生成样本之间的梯度范数，并加入惩罚项，确保判别器满足 Lipschitz 条件。</li></ul><h4 id="3-1-2-强化学习中的策略梯度"><a href="#3-1-2-强化学习中的策略梯度" class="headerlink" title="3.1.2 强化学习中的策略梯度"></a>3.1.2 强化学习中的策略梯度</h4><p>在强化学习中，策略梯度方法需要计算价值函数或优势函数对策略参数的梯度：</p><ul><li><strong>策略梯度定理</strong>：雅可比矩阵用于将轨迹的奖励信号反向传播到策略参数，计算参数更新方向。</li><li><strong>信赖域策略优化（TRPO）</strong>：通过限制策略更新的 KL 散度（可通过雅可比矩阵计算），确保策略更新不会过大，提高学习稳定性。</li></ul><h4 id="3-1-3-动态系统建模与控制"><a href="#3-1-3-动态系统建模与控制" class="headerlink" title="3.1.3 动态系统建模与控制"></a>3.1.3 动态系统建模与控制</h4><p>机器学习中的动态系统建模（如神经ODE）大量使用雅可比矩阵：</p><ul><li><strong>神经ODE</strong>：使用雅可比矩阵计算伴随状态，实现高效的反向传播。雅可比矩阵的迹（对于对角雅可比）用于计算系统的复杂度和稳定性指标。</li><li><strong>模型预测控制（MPC）</strong>：基于学习的动态模型，雅可比矩阵用于线性化非线性系统，求解最优控制序列。</li></ul><h4 id="3-1-4-计算机视觉中的应用"><a href="#3-1-4-计算机视觉中的应用" class="headerlink" title="3.1.4 计算机视觉中的应用"></a>3.1.4 计算机视觉中的应用</h4><ul><li><strong>图像变形</strong>：图像变换的雅可比矩阵用于分析像素位置的变化率，在图像配准、光流估计等任务中发挥重要作用。</li><li><strong>特征提取</strong>：卷积神经网络中的卷积核可以看作是局部特征提取的雅可比矩阵，用于捕捉图像的局部结构信息。</li></ul><h2 id="4-雅可比矩阵的计算方法比较"><a href="#4-雅可比矩阵的计算方法比较" class="headerlink" title="4. 雅可比矩阵的计算方法比较"></a>4. 雅可比矩阵的计算方法比较</h2><p>雅可比矩阵的计算方法主要有三种：</p><h3 id="4-1-解析计算"><a href="#4-1-解析计算" class="headerlink" title="4.1 解析计算"></a>4.1 解析计算</h3><p>通过数学推导直接得到雅可比矩阵的解析表达式。</p><ul><li><strong>优点</strong>：计算效率高，精度最高，无数值误差。</li><li><strong>缺点</strong>：对于复杂函数，推导过程繁琐且容易出错；难以自动化，不适合大规模系统。</li><li><strong>适用场景</strong>：简单函数、已知数学形式的系统（如机器人学中的正运动学）。</li></ul><h3 id="4-2-数值微分"><a href="#4-2-数值微分" class="headerlink" title="4.2 数值微分"></a>4.2 数值微分</h3><p>通过有限差分法近似计算偏导数：</p><p>$$\frac{\partial f_i}{\partial x_j} \approx \frac{f_i(x_j + h) - f_i(x_j - h)}{2h}$$（中心差分）</p><ul><li><strong>优点</strong>：实现简单，无需了解函数的数学形式；易于并行计算。</li><li><strong>缺点</strong>：存在截断误差（与 $h^2$ 成正比）和舍入误差；计算成本高（需要 $n \times m$ 次函数评估）。</li><li><strong>适用场景</strong>：函数形式未知、难以推导解析表达式的系统。</li></ul><h3 id="4-3-自动微分"><a href="#4-3-自动微分" class="headerlink" title="4.3 自动微分"></a>4.3 自动微分</h3><p>通过跟踪计算图，自动应用链式法则计算导数。分为前向模式和反向模式：</p><ul><li><p><strong>前向模式</strong>：对于每个输入维度，计算所有输出对该输入的导数。计算复杂度与输入维度成正比。</p></li><li><p><strong>反向模式</strong>：对于每个输出维度，计算该输出对所有输入的导数。计算复杂度与输出维度成正比，是深度学习中反向传播的基础。</p></li><li><p><strong>优点</strong>：结合了解析计算的精度和数值微分的通用性；计算效率高，误差可控制。</p></li><li><p><strong>缺点</strong>：需要特殊的编程框架支持（如 TensorFlow、PyTorch、JAX）；对于某些操作，实现复杂度较高。</p></li><li><p><strong>适用场景</strong>：大规模机器学习模型、复杂非线性系统的导数计算。</p></li></ul><h2 id="5-Eigen-示例计算（C-）"><a href="#5-Eigen-示例计算（C-）" class="headerlink" title="5. Eigen 示例计算（C++）"></a>5. Eigen 示例计算（C++）</h2><p>下面给出一个使用 Eigen 的完整示例：计算函数</p><p>$$<br>f_1(x,y)&#x3D;\sin(x) + x y,\qquad f_2(x,y)&#x3D;e^{y} - x^2<br>$$</p><p>在给定点的雅可比矩阵，并演示线性近似与 $J^T J$ 的计算。</p><p>保存为 <code>jacobian_example.cpp</code>：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;Eigen/Dense&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cmath&gt;</span></span><br><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> Eigen;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br><span class="hljs-type">double</span> x = <span class="hljs-number">0.5</span>;<br><span class="hljs-type">double</span> y = <span class="hljs-number">-0.2</span>;<br><br>Matrix2d J;<br><span class="hljs-built_in">J</span>(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>) = std::<span class="hljs-built_in">cos</span>(x) + y; <span class="hljs-comment">// df1/dx</span><br><span class="hljs-built_in">J</span>(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>) = x;              <span class="hljs-comment">// df1/dy</span><br><span class="hljs-built_in">J</span>(<span class="hljs-number">1</span>,<span class="hljs-number">0</span>) = <span class="hljs-number">-2.0</span>*x;         <span class="hljs-comment">// df2/dx</span><br><span class="hljs-built_in">J</span>(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>) = std::<span class="hljs-built_in">exp</span>(y);    <span class="hljs-comment">// df2/dy</span><br><br>std::cout &lt;&lt; <span class="hljs-string">&quot;Jacobian at (&quot;</span>&lt;&lt;x&lt;&lt;<span class="hljs-string">&quot;,&quot;</span>&lt;&lt;y&lt;&lt;<span class="hljs-string">&quot;):\n&quot;</span>&lt;&lt; J &lt;&lt; std::endl;<br><br><span class="hljs-comment">// 线性近似示例</span><br><span class="hljs-function">Vector2d <span class="hljs-title">dx</span><span class="hljs-params">(<span class="hljs-number">1e-3</span>, <span class="hljs-number">-2e-3</span>)</span></span>;<br>Vector2d df = J * dx;<br>std::cout &lt;&lt; <span class="hljs-string">&quot;Linear approx df:\n&quot;</span>&lt;&lt; df &lt;&lt; std::endl;<br><br><span class="hljs-comment">// 计算 J^T * J</span><br>Matrix2d JTJ = J.<span class="hljs-built_in">transpose</span>() * J;<br>std::cout &lt;&lt; <span class="hljs-string">&quot;J^T * J:\n&quot;</span>&lt;&lt; JTJ &lt;&lt; std::endl;<br><br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>编译与运行（示例命令）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">g++ -std=c++17 jacobian_example.cpp -I /path/to/eigen -O2 -o jacobian_example<br>./jacobian_example<br></code></pre></td></tr></table></figure><p>输出将显示在指定点处的雅可比矩阵、线性近似的输出增量以及 $J^T J$ 的值。</p><h2 id="6-雅可比矩阵在其他领域的应用"><a href="#6-雅可比矩阵在其他领域的应用" class="headerlink" title="6. 雅可比矩阵在其他领域的应用"></a>6. 雅可比矩阵在其他领域的应用</h2><p>雅可比矩阵的应用远不止机器人学和机器学习，它在科学和工程的许多领域都发挥着重要作用：</p><h3 id="6-1-流体力学"><a href="#6-1-流体力学" class="headerlink" title="6.1 流体力学"></a>6.1 流体力学</h3><p>在流体力学中，雅可比矩阵用于描述流体的变形率张量和应变率张量：</p><ul><li><strong>变形率张量</strong>：速度场的雅可比矩阵可以分解为对称的应变率张量和反对称的旋转张量。</li><li><strong>不可压缩流体</strong>：对于不可压缩流体，速度场的雅可比矩阵的迹为零（$\nabla \cdot \mathbf{u} &#x3D; 0$）。</li><li><strong>湍流模型</strong>：雅可比矩阵的特征值用于分析流体的局部稳定性和湍流生成机制。</li></ul><h3 id="6-2-电磁学"><a href="#6-2-电磁学" class="headerlink" title="6.2 电磁学"></a>6.2 电磁学</h3><ul><li><strong>Maxwell方程组的数值求解</strong>：在有限元法和有限差分法中，雅可比矩阵用于构建非线性方程组的迭代求解器。</li><li><strong>电磁参数反演</strong>：通过雅可比矩阵将测量数据与模型参数联系起来，用于地球物理勘探和材料特性评估。</li></ul><h3 id="6-3-计算机图形学"><a href="#6-3-计算机图形学" class="headerlink" title="6.3 计算机图形学"></a>6.3 计算机图形学</h3><ul><li><strong>动画与变形</strong>：角色动画中，雅可比矩阵用于控制骨骼动画的皮肤变形，确保变形的平滑性和物理合理性。</li><li><strong>碰撞检测</strong>：通过计算物体表面的雅可比矩阵，快速判断物体之间的碰撞和接触点。</li><li><strong>纹理映射</strong>：纹理坐标变换的雅可比矩阵用于调整纹理的缩放和扭曲，避免纹理拉伸。</li></ul><h3 id="6-4-生物医学工程"><a href="#6-4-生物医学工程" class="headerlink" title="6.4 生物医学工程"></a>6.4 生物医学工程</h3><ul><li><strong>医学成像</strong>：医学图像配准算法中，雅可比矩阵用于计算图像变换的变形率，评估配准的准确性。</li><li><strong>生物力学建模</strong>：人体骨骼和软组织的力学模型中，雅可比矩阵用于分析应力和应变的分布。</li></ul><h3 id="6-5-经济学与金融学"><a href="#6-5-经济学与金融学" class="headerlink" title="6.5 经济学与金融学"></a>6.5 经济学与金融学</h3><ul><li><strong>一般均衡理论</strong>：雅可比矩阵用于分析经济系统的稳定性和均衡点的存在性。</li><li><strong>风险管理</strong>：金融衍生品定价模型中，雅可比矩阵用于计算希腊字母（如Delta、Gamma），评估风险暴露。</li></ul><hr><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a>7. 总结</h2><p>雅可比矩阵是数学分析中一个强大的工具，它将非线性变换线性化，提供了局部近似的视角。从几何直观到实际应用，雅可比矩阵在机器人学、机器学习、流体力学、计算机图形学等众多领域都发挥着关键作用。</p><p>雅可比行列式作为雅可比矩阵的重要性质，提供了关于非线性变换的体积缩放信息，在积分变换、概率密度计算等方面具有广泛应用。</p><p>随着计算技术的发展，自动微分等高效计算方法的出现，使得雅可比矩阵在大规模系统中的应用变得更加可行。无论是理论研究还是工程实践，深入理解雅可比矩阵的概念和应用都将为解决复杂问题提供有力的数学工具。</p>]]></content>
    
    
    <categories>
      
      <category>数学笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Linux 计算过对比及优化过程</title>
    <link href="/2025/12/27/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/Linux%20%E8%AE%A1%E7%AE%97%E8%BF%87%E5%AF%B9%E6%AF%94%E5%8F%8A%E4%BC%98%E5%8C%96%E8%BF%87%E7%A8%8B/"/>
    <url>/2025/12/27/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/Linux%20%E8%AE%A1%E7%AE%97%E8%BF%87%E5%AF%B9%E6%AF%94%E5%8F%8A%E4%BC%98%E5%8C%96%E8%BF%87%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="test-foo：A-A-T-性能对比与优化分析（Eigen-vs-多层-for）"><a href="#test-foo：A-A-T-性能对比与优化分析（Eigen-vs-多层-for）" class="headerlink" title="test_foo：A * A^T 性能对比与优化分析（Eigen vs 多层 for）"></a>test_foo：A * A^T 性能对比与优化分析（Eigen vs 多层 for）</h1><h2 id="代码功能分析"><a href="#代码功能分析" class="headerlink" title="代码功能分析"></a>代码功能分析</h2><h3 id="文件功能概述"><a href="#文件功能概述" class="headerlink" title="文件功能概述"></a>文件功能概述</h3><p><code>test_foo.cc</code> 是一个性能基准测试程序，用于对比 <strong>Eigen 库</strong> 和 <strong>手动多层 for 循环</strong> 两种方法在计算对称矩阵乘法 <code>C = A * A^T</code> 时的性能差异。</p><p><strong>测试参数</strong>：</p><ul><li>输入矩阵：<code>A</code>，类型 <code>uint16_t</code>（实现中转为 <code>uint64_t</code> 防溢出）</li><li>维度：<code>A</code> 为 1080×1920</li><li>计算：<code>C = A * A^T</code></li><li>输出矩阵：<code>C</code>，维度 1080×1080（Gram 矩阵，天然对称）</li><li>计算量级：约 $1080\times1080\times1920 \approx 2.24\times 10^9$ 次乘加</li></ul><h3 id="核心功能模块"><a href="#核心功能模块" class="headerlink" title="核心功能模块"></a>核心功能模块</h3><h4 id="1-数据生成-make-fixed-u16-1080x1920"><a href="#1-数据生成-make-fixed-u16-1080x1920" class="headerlink" title="1. 数据生成 (make_fixed_u16_1080x1920)"></a>1. 数据生成 (<code>make_fixed_u16_1080x1920</code>)</h4><ul><li><strong>功能</strong>：生成固定的 1080×1920 的 <code>uint16_t</code> 矩阵数据</li><li><strong>特点</strong>：使用确定性算法（<code>i*131 + j*17 + 7</code>），确保结果可复现</li><li><strong>用途</strong>：避免全 0&#x2F;全 1 等特殊模式，提供真实的测试数据</li></ul><h4 id="2-Eigen-实现-eigen-rankupdate-selfadjoint-full"><a href="#2-Eigen-实现-eigen-rankupdate-selfadjoint-full" class="headerlink" title="2. Eigen 实现 (eigen_rankupdate_selfadjoint_full)"></a>2. Eigen 实现 (<code>eigen_rankupdate_selfadjoint_full</code>)</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs 112:124:tests/test_foo.cc">void eigen_rankupdate_selfadjoint_full(<br>    const Eigen::Matrix&lt;U64, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor&gt;&amp; a64,<br>    Eigen::Matrix&lt;U64, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor&gt;&amp; c_full) &#123;<br>    // 只更新一个三角，再镜像得到完整对称矩阵。<br>    c_full.setZero();<br>    c_full.template selfadjointView&lt;Eigen::Lower&gt;().rankUpdate(a64);<br><br>    for (int i = 0; i &lt; kH; ++i) &#123;<br>        for (int j = i + 1; j &lt; kH; ++j) &#123;<br>            c_full(i, j) = c_full(j, i);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li><strong>优化策略</strong>：<ul><li>使用 <code>selfadjointView&lt;Eigen::Lower&gt;().rankUpdate()</code> 只计算下三角</li><li>利用 Eigen 的对称矩阵优化路径（类似 BLAS SYRK）</li><li>手动镜像上三角部分</li></ul></li></ul><h4 id="3-多层-for-循环实现-matmul-self-loop-blocked-half"><a href="#3-多层-for-循环实现-matmul-self-loop-blocked-half" class="headerlink" title="3. 多层 for 循环实现 (matmul_self_loop_blocked_half)"></a>3. 多层 for 循环实现 (<code>matmul_self_loop_blocked_half</code>)</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs 72:110:tests/test_foo.cc">Eigen::Matrix&lt;U64, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor&gt; matmul_self_loop_blocked_half(<br>    const Eigen::Matrix&lt;U64, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor&gt;&amp; a64,<br>    bool enable_openmp) &#123;<br>    Eigen::Matrix&lt;U64, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor&gt; c(kH, kH);<br>    c.setZero();<br><br>    constexpr int kJBlock = 16;<br><br>#ifdef _OPENMP<br>#pragma omp parallel for schedule(static) if(enable_openmp)<br>#else<br>    (void)enable_openmp;<br>#endif<br>    for (int i = 0; i &lt; kH; ++i) &#123;<br>        const U64* row_i = a64.data() + static_cast&lt;std::size_t&gt;(i) * static_cast&lt;std::size_t&gt;(kW);<br><br>        // 只计算上三角（j &gt;= i），再镜像到下三角。<br>        for (int jb = i; jb &lt; kH; jb += kJBlock) &#123;<br>            const int j_end = (jb + kJBlock &lt; kH) ? (jb + kJBlock) : kH;<br>            U64 sums[kJBlock] = &#123;0&#125;;<br><br>            for (int k = 0; k &lt; kW; ++k) &#123;<br>                const U64 a_ik = row_i[k];<br>                for (int j = jb; j &lt; j_end; ++j) &#123;<br>                    const U64* row_j = a64.data() + static_cast&lt;std::size_t&gt;(j) * static_cast&lt;std::size_t&gt;(kW);<br>                    sums[j - jb] += a_ik * row_j[k];<br>                &#125;<br>            &#125;<br><br>            for (int j = jb; j &lt; j_end; ++j) &#123;<br>                const U64 v = sums[j - jb];<br>                c(i, j) = v;<br>                c(j, i) = v;<br>            &#125;<br>        &#125;<br>    &#125;<br><br>    return c;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li><strong>优化策略</strong>：<ul><li><strong>对称性利用</strong>：只计算上三角（<code>j &gt;= i</code>），然后镜像到下三角</li><li><strong>分块处理</strong>：<code>j</code> 维度按块大小 16 分块，提高缓存局部性</li><li><strong>OpenMP 并行</strong>：外层 <code>i</code> 循环可并行化，支持环境变量控制</li><li><strong>数据复用</strong>：内层 <code>k</code> 循环中，<code>a_ik</code> 被复用计算多个 <code>j</code></li></ul></li></ul><h4 id="4-性能测量-time-average-ms"><a href="#4-性能测量-time-average-ms" class="headerlink" title="4. 性能测量 (time_average_ms)"></a>4. 性能测量 (<code>time_average_ms</code>)</h4><ul><li><strong>方法</strong>：先预热 10 次，再执行 50 次测量取平均</li><li><strong>目的</strong>：消除冷启动、缓存预热等影响，获得稳定性能数据</li></ul><h4 id="5-结果验证-hash-matrix-u64"><a href="#5-结果验证-hash-matrix-u64" class="headerlink" title="5. 结果验证 (hash_matrix_u64)"></a>5. 结果验证 (<code>hash_matrix_u64</code>)</h4><ul><li><strong>方法</strong>：使用 FNV-1a 64 位哈希算法计算矩阵哈希值</li><li><strong>优势</strong>：避免逐元素比较，快速验证两种实现结果一致性</li></ul><h3 id="测试流程"><a href="#测试流程" class="headerlink" title="测试流程"></a>测试流程</h3><ol><li>生成固定的 1080×1920 <code>uint16_t</code> 矩阵</li><li>转换为 <code>uint64_t</code> 矩阵（防止溢出）</li><li>分别用 Eigen 和 Loop 方法计算 <code>C = A * A^T</code></li><li>比较两种方法的执行时间和结果一致性</li></ol><h2 id="优化实现与性能结果"><a href="#优化实现与性能结果" class="headerlink" title="优化实现与性能结果"></a>优化实现与性能结果</h2><h3 id="已实现的优化"><a href="#已实现的优化" class="headerlink" title="已实现的优化"></a>已实现的优化</h3><h4 id="Eigen-版本优化"><a href="#Eigen-版本优化" class="headerlink" title="Eigen 版本优化"></a>Eigen 版本优化</h4><ul><li><strong>对称性利用</strong>：使用 <code>selfadjointView().rankUpdate()</code> 只计算下三角，再镜像补全</li><li><strong>统计方式</strong>：warm up 10 次，再循环 50 次计时取平均</li></ul><h4 id="Loop-版本优化"><a href="#Loop-版本优化" class="headerlink" title="Loop 版本优化"></a>Loop 版本优化</h4><ul><li><strong>对称性利用</strong>：只算半边（<code>j&gt;=i</code>），再镜像到下三角</li><li><strong>分块优化</strong>：块大小 16，提高缓存局部性</li><li><strong>OpenMP 并行</strong>：外层 <code>i</code> 循环并行化（可通过环境变量 <code>NNDEPLOY_BENCH_DISABLE_OMP=1</code> 关闭）</li></ul><h3 id="最新实测结果（含-CUDA-OpenCL）"><a href="#最新实测结果（含-CUDA-OpenCL）" class="headerlink" title="最新实测结果（含 CUDA&#x2F;OpenCL）"></a>最新实测结果（含 CUDA&#x2F;OpenCL）</h3><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">u16 固定矩阵维度: <span class="hljs-number">1080</span>x1920<br>计算: C = A * A^T (结果维度 <span class="hljs-number">1080</span>x1080)<br><br>Eigen 用时: <span class="hljs-number">281.72</span> <span class="hljs-keyword">ms</span><br><span class="hljs-title">Loop</span>  用时: <span class="hljs-number">507.922</span> <span class="hljs-keyword">ms</span><br><span class="hljs-title">CUDA</span>  用时: <span class="hljs-number">43.6833</span> <span class="hljs-keyword">ms</span><br><span class="hljs-title">OpenCL</span> 用时: <span class="hljs-number">216.147</span> <span class="hljs-keyword">ms</span><br><br><span class="hljs-title">CUDA</span>  hash: <span class="hljs-number">6808166764559248003</span><br>OpenCL hash: <span class="hljs-number">6808166764559248003</span><br>Eigen hash: <span class="hljs-number">6808166764559248003</span><br>Loop  hash: <span class="hljs-number">6808166764559248003</span><br>结果一致: YES<br></code></pre></td></tr></table></figure><h4 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h4><ul><li><strong>所有实现（Eigen&#x2F;Loop&#x2F;CUDA&#x2F;OpenCL）结果完全一致，均通过哈希校验。</strong></li><li><strong>计时均为端到端耗时</strong>，即包括主机与设备间数据搬运、内核执行、结果回传等全部阶段。</li><li><strong>CUDA 性能最优</strong>，远超 OpenCL，主要因 NVIDIA 平台对 CUDA 优化更深，OpenCL 驱动和内核优化有限。</li><li><strong>OpenCL 性能优于 CPU，但明显慢于 CUDA</strong>，为 GPU 通用接口的典型表现。</li></ul><h3 id="优化效果"><a href="#优化效果" class="headerlink" title="优化效果"></a>优化效果</h3><ul><li><strong>Eigen 方案</strong>：性能提升显著（原约 564ms → 280ms，提升约 2 倍），充分利用了对称性和底层库加速</li><li><strong>Loop 方案</strong>：性能明显提升（原约 1190ms → 505ms，提升约 2.35 倍），分块和只算半边有效减少了计算量和缓存压力</li><li><strong>正确性</strong>：两者结果完全一致（哈希验证），说明优化未影响正确性</li></ul><blockquote><p><strong>说明</strong>：不同机器&#x2F;编译参数&#x2F;线程数&#x2F;CPU 调度会导致数值波动，上述数据仅供参考。</p></blockquote><h2 id="优化可行性分析"><a href="#优化可行性分析" class="headerlink" title="优化可行性分析"></a>优化可行性分析</h2><h3 id="当前实现的优化评估"><a href="#当前实现的优化评估" class="headerlink" title="当前实现的优化评估"></a>当前实现的优化评估</h3><h4 id="✅-Eigen-版本优化（已实现且可行）"><a href="#✅-Eigen-版本优化（已实现且可行）" class="headerlink" title="✅ Eigen 版本优化（已实现且可行）"></a>✅ Eigen 版本优化（已实现且可行）</h4><p><strong>实现方式</strong>：</p><ul><li>使用 <code>selfadjointView&lt;Eigen::Lower&gt;().rankUpdate(a64)</code> 计算下三角</li><li>手动镜像到上三角</li></ul><p><strong>可行性评估</strong>：</p><ul><li>✅ <strong>完全可行</strong>：Eigen 的 <code>rankUpdate</code> 专门为对称矩阵优化，计算量约为完整矩阵乘法的一半</li><li>✅ <strong>正确性保证</strong>：利用数学对称性（<code>C = A * A^T</code> 天然对称），镜像操作不会引入误差</li><li>✅ <strong>性能收益</strong>：实测从约 564ms 降至 280ms，提升约 2 倍</li></ul><p><strong>潜在改进空间</strong>：</p><ul><li>可考虑使用 <code>selfadjointView&lt;Eigen::Upper&gt;()</code> 配合不同布局，但收益有限</li><li>如果链接高性能 BLAS（如 MKL&#x2F;OpenBLAS），<code>rankUpdate</code> 会自动使用优化的 SYRK 内核</li></ul><h4 id="✅-Loop-版本优化（已实现且可行）"><a href="#✅-Loop-版本优化（已实现且可行）" class="headerlink" title="✅ Loop 版本优化（已实现且可行）"></a>✅ Loop 版本优化（已实现且可行）</h4><p><strong>实现方式</strong>：</p><ol><li><strong>对称性利用</strong>：只计算 <code>j &gt;= i</code> 的上三角部分</li><li><strong>分块优化</strong>：<code>j</code> 维度按块大小 16 分块处理</li><li><strong>OpenMP 并行</strong>：外层 <code>i</code> 循环并行化</li></ol><p><strong>可行性评估</strong>：</p><ol><li><p><strong>对称性优化</strong> ✅</p><ul><li><strong>数学正确性</strong>：<code>C(i,j) = C(j,i)</code> 对于 <code>A * A^T</code> 恒成立</li><li><strong>计算量减少</strong>：理论上减少约 50% 的乘加运算</li><li><strong>实现简单</strong>：只需改变循环边界和添加镜像操作</li><li><strong>实测效果</strong>：从约 1190ms 降至 505ms，提升约 2.35 倍</li></ul></li><li><p><strong>分块优化</strong> ✅</p><ul><li><strong>缓存友好性</strong>：块大小 16 使得 <code>sums[kJBlock]</code> 数组（128 字节）能很好地适配 L1 缓存</li><li><strong>数据复用</strong>：内层 <code>k</code> 循环中，<code>a_ik</code> 被复用计算多个 <code>j</code>，提高计算密度</li><li><strong>指令级并行</strong>：多个 <code>sums[j]</code> 的累加可以并行执行</li><li><strong>可调参数</strong>：块大小可根据目标 CPU 缓存特性调整（8&#x2F;16&#x2F;32&#x2F;64）</li></ul></li><li><p><strong>OpenMP 并行</strong> ✅</p><ul><li><strong>数据独立性</strong>：外层 <code>i</code> 循环之间无数据依赖，天然可并行</li><li><strong>负载均衡</strong>：<code>schedule(static)</code> 适合计算量均匀的场景</li><li><strong>环境控制</strong>：通过 <code>NNDEPLOY_BENCH_DISABLE_OMP</code> 环境变量可灵活开关</li><li><strong>注意事项</strong>：需确保与 Eigen 版本使用相同的线程策略进行公平对比</li></ul></li></ol><h3 id="进一步优化方向评估"><a href="#进一步优化方向评估" class="headerlink" title="进一步优化方向评估"></a>进一步优化方向评估</h3><h4 id="1-更大块分块-⚠️-需测试"><a href="#1-更大块分块-⚠️-需测试" class="headerlink" title="1. 更大块分块 ⚠️ 需测试"></a>1. 更大块分块 ⚠️ 需测试</h4><ul><li><strong>可行性</strong>：块大小可调整为 32&#x2F;64&#x2F;128</li><li><strong>风险</strong>：块过大可能导致 L1 缓存溢出，反而降低性能</li><li><strong>建议</strong>：通过基准测试找到最优块大小（通常与 CPU 缓存行大小相关）</li></ul><h4 id="2-K-维度分块-✅-可行"><a href="#2-K-维度分块-✅-可行" class="headerlink" title="2. K 维度分块 ✅ 可行"></a>2. K 维度分块 ✅ 可行</h4><ul><li><strong>思路</strong>：对 <code>k</code> 维度也进行分块，进一步提高缓存局部性</li><li><strong>实现</strong>：在现有 <code>j</code> 分块基础上，增加 <code>k</code> 维度的分块循环</li><li><strong>收益</strong>：对于大矩阵（kW&#x3D;1920），可能显著减少内存访问</li><li><strong>复杂度</strong>：需要三层分块嵌套，代码复杂度增加</li></ul><h4 id="3-手动向量化（SIMD）✅-可行但复杂"><a href="#3-手动向量化（SIMD）✅-可行但复杂" class="headerlink" title="3. 手动向量化（SIMD）✅ 可行但复杂"></a>3. 手动向量化（SIMD）✅ 可行但复杂</h4><ul><li><strong>可行性</strong>：使用 AVX2&#x2F;AVX-512 指令集手动优化内层循环</li><li><strong>收益</strong>：理论上可提升 4-8 倍（取决于 SIMD 宽度）</li><li><strong>成本</strong>：需要平台特定代码，维护成本高</li><li><strong>替代方案</strong>：依赖编译器自动向量化（<code>-march=native -O3</code>）</li></ul><h4 id="4-更高级的并行策略-⚠️-需权衡"><a href="#4-更高级的并行策略-⚠️-需权衡" class="headerlink" title="4. 更高级的并行策略 ⚠️ 需权衡"></a>4. 更高级的并行策略 ⚠️ 需权衡</h4><ul><li><strong>动态调度</strong>：<code>schedule(dynamic)</code> 可能在某些场景下更好</li><li><strong>嵌套并行</strong>：对 <code>j</code> 块也并行化，但可能引入线程开销</li><li><strong>NUMA 感知</strong>：多插槽系统需要考虑内存亲和性</li></ul><h3 id="优化建议总结"><a href="#优化建议总结" class="headerlink" title="优化建议总结"></a>优化建议总结</h3><table><thead><tr><th>优化方向</th><th>可行性</th><th>实现难度</th><th>预期收益</th><th>推荐优先级</th></tr></thead><tbody><tr><td>对称性利用（已实现）</td><td>✅ 高</td><td>低</td><td>高（~2x）</td><td>⭐⭐⭐⭐⭐</td></tr><tr><td>分块优化（已实现）</td><td>✅ 高</td><td>中</td><td>中（~1.2-1.5x）</td><td>⭐⭐⭐⭐</td></tr><tr><td>OpenMP 并行（已实现）</td><td>✅ 高</td><td>低</td><td>高（多核场景）</td><td>⭐⭐⭐⭐</td></tr><tr><td>K 维度分块</td><td>✅ 中</td><td>中</td><td>中（~1.2-1.3x）</td><td>⭐⭐⭐</td></tr><tr><td>更大块分块</td><td>⚠️ 需测试</td><td>低</td><td>低-中</td><td>⭐⭐</td></tr><tr><td>手动 SIMD</td><td>✅ 高</td><td>高</td><td>高（~2-4x）</td><td>⭐⭐</td></tr><tr><td>链接高性能 BLAS</td><td>✅ 高</td><td>低</td><td>很高（~2-5x）</td><td>⭐⭐⭐⭐⭐</td></tr></tbody></table><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p><strong>当前实现的优化完全可行且有效</strong>：</p><ul><li>✅ 数学正确性：对称性利用基于严格的数学性质</li><li>✅ 性能提升显著：Eigen 版本提升约 2 倍，Loop 版本提升约 2.35 倍</li><li>✅ 结果一致性：两种方法结果完全一致（哈希验证）</li><li>✅ 代码质量：实现清晰，可维护性好</li></ul><p><strong>推荐下一步</strong>：</p><ol><li><strong>短期</strong>：尝试调整块大小（8&#x2F;16&#x2F;32&#x2F;64），找到最优值</li><li><strong>中期</strong>：实现 K 维度分块，进一步提升缓存效率</li><li><strong>长期</strong>：如果允许外部依赖，链接 OpenBLAS&#x2F;MKL 可获得最大性能提升</li></ol><h2 id="通用优化建议"><a href="#通用优化建议" class="headerlink" title="通用优化建议"></a>通用优化建议</h2><h3 id="编译与构建选项"><a href="#编译与构建选项" class="headerlink" title="编译与构建选项"></a>编译与构建选项</h3><p>优先确保 <strong>Release + 高优化</strong>：</p><ul><li><code>-O3 -DNDEBUG</code></li><li><code>-march=native</code>（在目标机器本地编译时）</li></ul><p>说明：本基准主要是整数乘加，<code>-ffast-math</code> 对浮点更相关，这里不属于第一优先级。</p><h3 id="线程-核绑定与频率稳定"><a href="#线程-核绑定与频率稳定" class="headerlink" title="线程&#x2F;核绑定与频率稳定"></a>线程&#x2F;核绑定与频率稳定</h3><ul><li>想要 <strong>可复现</strong> 的对比：建议两边统一为单线程，并绑定固定 CPU 核</li><li>想要 <strong>最快</strong>：则允许 Eigen&#x2F;BLAS&#x2F;for-loop 并行吃满 CPU</li></ul><p>常用方法：</p><ul><li>绑核：<code>taskset -c 0 ./UnitTestFoo</code></li><li>统一 OpenMP 线程：<code>OMP_NUM_THREADS=1</code></li><li>若使用 OpenBLAS：<code>OPENBLAS_NUM_THREADS=1</code></li></ul><blockquote><p>建议在对比时明确写清：是否绑核、线程数、是否开启睿频&#x2F;性能模式。</p></blockquote><h3 id="测量方法"><a href="#测量方法" class="headerlink" title="测量方法"></a>测量方法</h3><ul><li>预热：首次运行常包含冷缓存、缺页、动态库初始化等开销</li><li>多次测量：建议跑 3~10 次，取最小值或中位数</li></ul><h2 id="性能瓶颈分析"><a href="#性能瓶颈分析" class="headerlink" title="性能瓶颈分析"></a>性能瓶颈分析</h2><p>该计算的性能瓶颈主要来自：</p><ol><li><strong>计算量巨大</strong>：约 $2.24\times 10^9$ 次乘加运算</li><li><strong>内存带宽</strong>：需要频繁访问大量矩阵数据</li><li><strong>缓存效率</strong>：矩阵尺寸较大，容易产生缓存 miss</li><li><strong>并行度</strong>：是否能充分利用 SIMD（向量化）与多核</li></ol><p>因此优化方向应聚焦于：</p><ul><li>利用对称性减少一半计算</li><li>提高缓存访问友好性（分块、数据复用）</li><li>充分利用 SIMD 向量化和多核并行</li></ul>]]></content>
    
    
    <categories>
      
      <category>性能优化</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>CPU性能分析与优化</title>
    <link href="/2024/05/06/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/CPU%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96/"/>
    <url>/2024/05/06/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/CPU%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h2 id="现代CPU性能分析"><a href="#现代CPU性能分析" class="headerlink" title="现代CPU性能分析"></a>现代CPU性能分析</h2><h3 id="性能测量"><a href="#性能测量" class="headerlink" title="性能测量"></a>性能测量</h3><p>理解应用程序性能的第一步是学会对它进行测量，基准测试每次运行的结果都不尽相同，因为在性能测量中存在误差，性能分析通常需要通过统计方法进行处理。<br>设计性能测试和配置测试环境都是性能评估工作的重要组成部分。</p><h4 id="现代系统中的噪声"><a href="#现代系统中的噪声" class="headerlink" title="现代系统中的噪声"></a>现代系统中的噪声</h4><p>以动态频率调节（DFS）为例，它是一个在短时间内提升CPU频率让其运行速度明显加快的特性。但是，CPU不能长时间处于“超频”状态，稍后它会降低到基本值。DFS很大程度上由CPU核的温度决定，因此很难预测其对实验结果的影响。</p><p>经验：即使运行任务管理工具-例如TOP指令，也会影响测量结果，因为某些CPU核会被激活并分配给该工具的进程，这可能会影响运                                                                                        </p><h4 id="手动性能测试"><a href="#手动性能测试" class="headerlink" title="手动性能测试"></a>手动性能测试</h4><p>正常提交变更代码时，我们需要确保性能没有退化，一般通过以下三步完成：<br>1、测量基线性能；<br>2、测量修改后程序的性能；<br>3、对两者进行比较；</p><h4 id="软件计时器和硬件计时器"><a href="#软件计时器和硬件计时器" class="headerlink" title="软件计时器和硬件计时器"></a>软件计时器和硬件计时器</h4><p>1、系统级高分辨率计时器：系统计时器，通过统计自某任意时间起开始流逝的滴答数而实现。在Linux操作系统下，可通过clock_gettime系统调用访问系统计时器；在C++语言中，标准的做法是使用std::chrono访问系统计时器。<br>2、时间戳计时器（TSC），这是一个通过硬件寄存器实现的硬件计时器。TSC也是单调递增的，并且以固定的速率增长，也就是说它与频率无关。TSC的值可以使用编译器的内置函数__rdtsc查询。</p><p>CppPerformanceBenchmarks：<a href="https://gitlab.com/chriscox/CppPerformanceBenchmarks">https://gitlab.com/chriscox/CppPerformanceBenchmarks</a> 介绍了不同平台下使用不同API调用计时器的性能比较。</p><h4 id="微基准测试"><a href="#微基准测试" class="headerlink" title="微基准测试"></a>微基准测试</h4><p>为了验证某些假设，可以编写一个独立的微基准测试程序。通常，微基准测试程序是在优化某些特定功能时跟踪优化进展的手段。几乎所有现代编程语言都有基准测试框架，比如对C++来说可以使用Google Benchmark库，<a href="https://github.com/google/benchmark%E3%80%82">https://github.com/google/benchmark。</a></p><p>写基准测试程序时，重要的是确保测试场景在微基准测试程序运行时执行。优化编译器可能会消除使实验变得无用的代码（编译器优化掉）。防止编译器优化重要代码的一种常用手段是，使用类似 DoNotoptimize的辅助函数，这些辅助函数可以在幕后完成必要的内联汇编优化。</p><p>检验这件事的方式：审视一下基准测试的性能剖析文件，看看关注的代码是否凸显微热点。</p><p>性能数据分布之间的统计可以通过假设检验方法来识别和发现。一旦确定性能差异在统计上是显著的，那么性能加速比可以通过算术平均或几何平均来计算。</p><h3 id="CPU微架构"><a href="#CPU微架构" class="headerlink" title="CPU微架构"></a>CPU微架构</h3><h3 id="性能分析中的术语和指标"><a href="#性能分析中的术语和指标" class="headerlink" title="性能分析中的术语和指标"></a>性能分析中的术语和指标</h3><h3 id="性能分析方法"><a href="#性能分析方法" class="headerlink" title="性能分析方法"></a>性能分析方法</h3><h3 id="性能分析相关的CPU特性"><a href="#性能分析相关的CPU特性" class="headerlink" title="性能分析相关的CPU特性"></a>性能分析相关的CPU特性</h3><h2 id="基于源代码的CPU调优"><a href="#基于源代码的CPU调优" class="headerlink" title="基于源代码的CPU调优"></a>基于源代码的CPU调优</h2><h3 id="CPU前端优化"><a href="#CPU前端优化" class="headerlink" title="CPU前端优化"></a>CPU前端优化</h3><h3 id="CPU后端优化"><a href="#CPU后端优化" class="headerlink" title="CPU后端优化"></a>CPU后端优化</h3><h3 id="优化错误投机"><a href="#优化错误投机" class="headerlink" title="优化错误投机"></a>优化错误投机</h3><h3 id="其他调优"><a href="#其他调优" class="headerlink" title="其他调优"></a>其他调优</h3><h3 id="优化多线程应用程序"><a href="#优化多线程应用程序" class="headerlink" title="优化多线程应用程序"></a>优化多线程应用程序</h3>]]></content>
    
    
    <categories>
      
      <category>性能优化</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>GPU内存的理解与基本使用</title>
    <link href="/2024/05/03/GPU/00_GPU%E5%86%85%E5%AD%98%E7%9A%84%E7%90%86%E8%A7%A3%E4%B8%8E%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"/>
    <url>/2024/05/03/GPU/00_GPU%E5%86%85%E5%AD%98%E7%9A%84%E7%90%86%E8%A7%A3%E4%B8%8E%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>GPU</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello C++</title>
    <link href="/2024/05/03/CPP/c++/"/>
    <url>/2024/05/03/CPP/c++/</url>
    
    <content type="html"><![CDATA[<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br>    std::cout &lt;&lt; <span class="hljs-string">&quot;hello world&quot;</span> &lt;&lt; std::endl;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="c-新特性"><a href="#c-新特性" class="headerlink" title="c++新特性"></a>c++新特性</h3><p>C++11 ~ C++23 主要新特性与示例：</p><h4 id="C-11"><a href="#C-11" class="headerlink" title="C++11"></a>C++11</h4><ul><li><strong>auto 关键字</strong><br>  自动类型推断。  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">auto</span> x = <span class="hljs-number">1</span>; <span class="hljs-comment">// x 推断为 int</span><br></code></pre></td></tr></table></figure></li><li><strong>范围for循环</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> v : &#123;<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>&#125;) std::cout &lt;&lt; v &lt;&lt; std::endl;<br></code></pre></td></tr></table></figure></li><li><strong>lambda 表达式</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">auto</span> add = [](<span class="hljs-type">int</span> a, <span class="hljs-type">int</span> b)&#123; <span class="hljs-keyword">return</span> a + b; &#125;;<br>std::cout &lt;&lt; <span class="hljs-built_in">add</span>(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>);<br></code></pre></td></tr></table></figure></li><li><strong>智能指针</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;memory&gt;</span></span><br>std::unique_ptr&lt;<span class="hljs-type">int</span>&gt; p = std::<span class="hljs-built_in">make_unique</span>&lt;<span class="hljs-type">int</span>&gt;(<span class="hljs-number">10</span>);<br></code></pre></td></tr></table></figure></li><li><strong>右值引用与移动语义</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">foo</span><span class="hljs-params">(std::string&amp;&amp; s)</span> </span>&#123; std::cout &lt;&lt; s; &#125;<br><span class="hljs-built_in">foo</span>(std::<span class="hljs-built_in">move</span>(std::<span class="hljs-built_in">string</span>(<span class="hljs-string">&quot;abc&quot;</span>)));<br></code></pre></td></tr></table></figure></li></ul><h4 id="C-14"><a href="#C-14" class="headerlink" title="C++14"></a>C++14</h4><ul><li><strong>泛型lambda</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">auto</span> f = [](<span class="hljs-keyword">auto</span> a, <span class="hljs-keyword">auto</span> b)&#123; <span class="hljs-keyword">return</span> a + b; &#125;;<br>std::cout &lt;&lt; <span class="hljs-built_in">f</span>(<span class="hljs-number">1</span>, <span class="hljs-number">2.5</span>);<br></code></pre></td></tr></table></figure></li><li><strong>二进制字面量</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">int</span> n = <span class="hljs-number">0b1010</span>; <span class="hljs-comment">// 10</span><br></code></pre></td></tr></table></figure></li><li><strong>返回值类型自动推断</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-keyword">auto</span> <span class="hljs-title">func</span><span class="hljs-params">()</span> </span>&#123; <span class="hljs-keyword">return</span> <span class="hljs-number">42</span>; &#125;<br></code></pre></td></tr></table></figure></li></ul><h4 id="C-17"><a href="#C-17" class="headerlink" title="C++17"></a>C++17</h4><ul><li><strong>结构化绑定</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++">std::tuple&lt;<span class="hljs-type">int</span>, <span class="hljs-type">double</span>&gt; t&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2.3</span>&#125;;<br><span class="hljs-keyword">auto</span> [a, b] = t;<br></code></pre></td></tr></table></figure></li><li><strong>if&#x2F;switch语句初始化</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">if</span> (<span class="hljs-type">int</span> x = <span class="hljs-number">5</span>; x &gt; <span class="hljs-number">3</span>) std::cout &lt;&lt; x;<br></code></pre></td></tr></table></figure></li><li><strong>内联变量</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">inline</span> <span class="hljs-type">int</span> x = <span class="hljs-number">10</span>;<br></code></pre></td></tr></table></figure></li><li><strong>std::optional&#x2F;std::variant&#x2F;std::any</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;optional&gt;</span></span><br>std::optional&lt;<span class="hljs-type">int</span>&gt; o = <span class="hljs-number">5</span>;<br></code></pre></td></tr></table></figure></li></ul><h4 id="C-20"><a href="#C-20" class="headerlink" title="C++20"></a>C++20</h4><ul><li><strong>concepts 概念</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">typename</span> T&gt;<br><span class="hljs-keyword">concept</span> Addable = <span class="hljs-built_in">requires</span>(T a, T b) &#123; a + b; &#125;;<br></code></pre></td></tr></table></figure></li><li><strong>范围（ranges）库</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;ranges&gt;</span></span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i : std::views::<span class="hljs-built_in">iota</span>(<span class="hljs-number">1</span>, <span class="hljs-number">5</span>)) std::cout &lt;&lt; i;<br></code></pre></td></tr></table></figure></li><li><strong>协程（coroutine）</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;coroutine&gt;</span></span><br><span class="hljs-comment">// 简单协程示例略</span><br></code></pre></td></tr></table></figure></li><li><strong>三路比较符 &lt;&#x3D;&gt;（太空船操作符）</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">auto</span> res = <span class="hljs-number">1</span> &lt;=&gt; <span class="hljs-number">2</span>;<br></code></pre></td></tr></table></figure></li><li><strong>模块化（modules）</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// module; import; export 语法</span><br></code></pre></td></tr></table></figure></li></ul><h4 id="C-23"><a href="#C-23" class="headerlink" title="C++23"></a>C++23</h4><ul><li><strong>多维下标运算符</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">Matrix</span> &#123;<br>    <span class="hljs-type">int</span> <span class="hljs-keyword">operator</span>[](<span class="hljs-type">size_t</span> i, <span class="hljs-type">size_t</span> j) <span class="hljs-type">const</span> &#123; <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>; &#125;<br>&#125;;<br></code></pre></td></tr></table></figure></li><li><strong>std::expected</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;expected&gt;</span></span><br>std::expected&lt;<span class="hljs-type">int</span>, std::string&gt; e = <span class="hljs-number">42</span>;<br></code></pre></td></tr></table></figure></li><li><strong>范围for循环支持初始化</strong>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; <span class="hljs-keyword">auto</span> v : &#123;<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>&#125;) std::cout &lt;&lt; i++ &lt;&lt; v;<br></code></pre></td></tr></table></figure></li></ul><p>更多细节可参考官方文档。</p>]]></content>
    
    
    <categories>
      
      <category>C++20</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
